{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# from torchvision.utils import save_image\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "image_size = 784\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 15\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "dataset = torchvision.datasets.MNIST(root='data/',\n",
    "                                     train=True,\n",
    "                                     transform=transforms.ToTensor(),\n",
    "                                     download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var\n",
    "model = VAE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunxin/miniconda3/envs/qhmtorch/lib/python3.7/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/sunxin/miniconda3/envs/qhmtorch/lib/python3.7/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/15], Step [10/469], Reconst Loss: 37740.8555, KL Div: 1798.6213\n",
      "Epoch[1/15], Step [20/469], Reconst Loss: 29012.0176, KL Div: 1156.0276\n",
      "Epoch[1/15], Step [30/469], Reconst Loss: 27721.3379, KL Div: 1266.7258\n",
      "Epoch[1/15], Step [40/469], Reconst Loss: 27496.0859, KL Div: 623.0237\n",
      "Epoch[1/15], Step [50/469], Reconst Loss: 27344.0078, KL Div: 570.0269\n",
      "Epoch[1/15], Step [60/469], Reconst Loss: 25651.9805, KL Div: 874.6756\n",
      "Epoch[1/15], Step [70/469], Reconst Loss: 24326.7012, KL Div: 1017.8434\n",
      "Epoch[1/15], Step [80/469], Reconst Loss: 24102.8691, KL Div: 1060.4421\n",
      "Epoch[1/15], Step [90/469], Reconst Loss: 23295.4609, KL Div: 1351.4631\n",
      "Epoch[1/15], Step [100/469], Reconst Loss: 22085.7578, KL Div: 1405.9507\n",
      "Epoch[1/15], Step [110/469], Reconst Loss: 20905.8926, KL Div: 1500.4385\n",
      "Epoch[1/15], Step [120/469], Reconst Loss: 20078.9023, KL Div: 1495.3447\n",
      "Epoch[1/15], Step [130/469], Reconst Loss: 20287.6035, KL Div: 1679.9824\n",
      "Epoch[1/15], Step [140/469], Reconst Loss: 19691.8184, KL Div: 1704.7559\n",
      "Epoch[1/15], Step [150/469], Reconst Loss: 19709.4551, KL Div: 1934.0181\n",
      "Epoch[1/15], Step [160/469], Reconst Loss: 18815.8574, KL Div: 1797.9963\n",
      "Epoch[1/15], Step [170/469], Reconst Loss: 18690.2578, KL Div: 1882.9237\n",
      "Epoch[1/15], Step [180/469], Reconst Loss: 17433.1523, KL Div: 2027.8387\n",
      "Epoch[1/15], Step [190/469], Reconst Loss: 17454.0840, KL Div: 2047.1534\n",
      "Epoch[1/15], Step [200/469], Reconst Loss: 16754.0156, KL Div: 2044.8755\n",
      "Epoch[1/15], Step [210/469], Reconst Loss: 16568.3086, KL Div: 2182.3677\n",
      "Epoch[1/15], Step [220/469], Reconst Loss: 17367.5039, KL Div: 1956.9041\n",
      "Epoch[1/15], Step [230/469], Reconst Loss: 16630.7305, KL Div: 2220.9663\n",
      "Epoch[1/15], Step [240/469], Reconst Loss: 16662.3027, KL Div: 2151.5513\n",
      "Epoch[1/15], Step [250/469], Reconst Loss: 16124.1875, KL Div: 2346.6553\n",
      "Epoch[1/15], Step [260/469], Reconst Loss: 16709.8711, KL Div: 2216.3877\n",
      "Epoch[1/15], Step [270/469], Reconst Loss: 16066.4707, KL Div: 2364.4370\n",
      "Epoch[1/15], Step [280/469], Reconst Loss: 15880.0918, KL Div: 2265.6772\n",
      "Epoch[1/15], Step [290/469], Reconst Loss: 15674.6211, KL Div: 2394.6367\n",
      "Epoch[1/15], Step [300/469], Reconst Loss: 15559.6484, KL Div: 2281.3716\n",
      "Epoch[1/15], Step [310/469], Reconst Loss: 15844.0830, KL Div: 2236.3372\n",
      "Epoch[1/15], Step [320/469], Reconst Loss: 14582.8252, KL Div: 2360.1316\n",
      "Epoch[1/15], Step [330/469], Reconst Loss: 15046.7207, KL Div: 2377.8115\n",
      "Epoch[1/15], Step [340/469], Reconst Loss: 15295.2461, KL Div: 2437.5110\n",
      "Epoch[1/15], Step [350/469], Reconst Loss: 14749.3340, KL Div: 2448.0403\n",
      "Epoch[1/15], Step [360/469], Reconst Loss: 14970.1045, KL Div: 2477.7053\n",
      "Epoch[1/15], Step [370/469], Reconst Loss: 14996.1895, KL Div: 2396.2158\n",
      "Epoch[1/15], Step [380/469], Reconst Loss: 14620.1699, KL Div: 2514.5713\n",
      "Epoch[1/15], Step [390/469], Reconst Loss: 14958.5820, KL Div: 2467.0547\n",
      "Epoch[1/15], Step [400/469], Reconst Loss: 14757.5508, KL Div: 2577.3403\n",
      "Epoch[1/15], Step [410/469], Reconst Loss: 13888.5488, KL Div: 2609.8320\n",
      "Epoch[1/15], Step [420/469], Reconst Loss: 14213.0820, KL Div: 2529.1240\n",
      "Epoch[1/15], Step [430/469], Reconst Loss: 14972.4971, KL Div: 2470.2466\n",
      "Epoch[1/15], Step [440/469], Reconst Loss: 13783.5840, KL Div: 2569.6570\n",
      "Epoch[1/15], Step [450/469], Reconst Loss: 13755.8535, KL Div: 2546.6177\n",
      "Epoch[1/15], Step [460/469], Reconst Loss: 13571.0596, KL Div: 2669.9141\n",
      "Epoch[2/15], Step [10/469], Reconst Loss: 14031.1309, KL Div: 2683.7800\n",
      "Epoch[2/15], Step [20/469], Reconst Loss: 13590.2539, KL Div: 2592.9851\n",
      "Epoch[2/15], Step [30/469], Reconst Loss: 13626.6484, KL Div: 2706.5728\n",
      "Epoch[2/15], Step [40/469], Reconst Loss: 13729.8467, KL Div: 2513.0996\n",
      "Epoch[2/15], Step [50/469], Reconst Loss: 13235.2168, KL Div: 2609.6548\n",
      "Epoch[2/15], Step [60/469], Reconst Loss: 13449.3330, KL Div: 2617.0649\n",
      "Epoch[2/15], Step [70/469], Reconst Loss: 13285.1826, KL Div: 2658.4814\n",
      "Epoch[2/15], Step [80/469], Reconst Loss: 13152.1729, KL Div: 2739.8174\n",
      "Epoch[2/15], Step [90/469], Reconst Loss: 13791.6455, KL Div: 2620.9229\n",
      "Epoch[2/15], Step [100/469], Reconst Loss: 12572.1426, KL Div: 2835.3638\n",
      "Epoch[2/15], Step [110/469], Reconst Loss: 12874.1914, KL Div: 2748.7495\n",
      "Epoch[2/15], Step [120/469], Reconst Loss: 13644.0244, KL Div: 2798.5752\n",
      "Epoch[2/15], Step [130/469], Reconst Loss: 13106.2734, KL Div: 2722.5269\n",
      "Epoch[2/15], Step [140/469], Reconst Loss: 13036.6182, KL Div: 2750.8379\n",
      "Epoch[2/15], Step [150/469], Reconst Loss: 12947.4668, KL Div: 2863.8530\n",
      "Epoch[2/15], Step [160/469], Reconst Loss: 12962.2881, KL Div: 2797.1243\n",
      "Epoch[2/15], Step [170/469], Reconst Loss: 13771.2969, KL Div: 2873.1011\n",
      "Epoch[2/15], Step [180/469], Reconst Loss: 12454.9551, KL Div: 2842.7622\n",
      "Epoch[2/15], Step [190/469], Reconst Loss: 12363.3369, KL Div: 2876.6887\n",
      "Epoch[2/15], Step [200/469], Reconst Loss: 12660.2188, KL Div: 2848.5779\n",
      "Epoch[2/15], Step [210/469], Reconst Loss: 12543.5938, KL Div: 2793.8518\n",
      "Epoch[2/15], Step [220/469], Reconst Loss: 12928.1426, KL Div: 2955.0056\n",
      "Epoch[2/15], Step [230/469], Reconst Loss: 12247.0879, KL Div: 2781.2952\n",
      "Epoch[2/15], Step [240/469], Reconst Loss: 12052.2090, KL Div: 2932.9492\n",
      "Epoch[2/15], Step [250/469], Reconst Loss: 12541.5137, KL Div: 2907.5159\n",
      "Epoch[2/15], Step [260/469], Reconst Loss: 12957.9951, KL Div: 2899.0813\n",
      "Epoch[2/15], Step [270/469], Reconst Loss: 12281.9482, KL Div: 2896.1975\n",
      "Epoch[2/15], Step [280/469], Reconst Loss: 12317.4307, KL Div: 2885.6807\n",
      "Epoch[2/15], Step [290/469], Reconst Loss: 12081.2305, KL Div: 2881.4019\n",
      "Epoch[2/15], Step [300/469], Reconst Loss: 12691.5117, KL Div: 2949.3247\n",
      "Epoch[2/15], Step [310/469], Reconst Loss: 12238.0498, KL Div: 2970.8948\n",
      "Epoch[2/15], Step [320/469], Reconst Loss: 12542.4014, KL Div: 3022.9521\n",
      "Epoch[2/15], Step [330/469], Reconst Loss: 12622.2051, KL Div: 2907.3691\n",
      "Epoch[2/15], Step [340/469], Reconst Loss: 12597.7158, KL Div: 2816.6135\n",
      "Epoch[2/15], Step [350/469], Reconst Loss: 12193.0859, KL Div: 2993.4807\n",
      "Epoch[2/15], Step [360/469], Reconst Loss: 12178.2529, KL Div: 2909.5930\n",
      "Epoch[2/15], Step [370/469], Reconst Loss: 12414.5957, KL Div: 3041.6611\n",
      "Epoch[2/15], Step [380/469], Reconst Loss: 12207.1309, KL Div: 2993.7344\n",
      "Epoch[2/15], Step [390/469], Reconst Loss: 12243.8926, KL Div: 2986.9285\n",
      "Epoch[2/15], Step [400/469], Reconst Loss: 12280.8174, KL Div: 3031.3635\n",
      "Epoch[2/15], Step [410/469], Reconst Loss: 12119.4453, KL Div: 2927.4990\n",
      "Epoch[2/15], Step [420/469], Reconst Loss: 12408.4805, KL Div: 2913.9810\n",
      "Epoch[2/15], Step [430/469], Reconst Loss: 11968.5527, KL Div: 2954.0151\n",
      "Epoch[2/15], Step [440/469], Reconst Loss: 12095.2500, KL Div: 3009.7100\n",
      "Epoch[2/15], Step [450/469], Reconst Loss: 11917.3193, KL Div: 3016.2090\n",
      "Epoch[2/15], Step [460/469], Reconst Loss: 12072.1084, KL Div: 2917.2510\n",
      "Epoch[3/15], Step [10/469], Reconst Loss: 12560.6572, KL Div: 2893.6272\n",
      "Epoch[3/15], Step [20/469], Reconst Loss: 12291.1855, KL Div: 3027.3691\n",
      "Epoch[3/15], Step [30/469], Reconst Loss: 12172.6562, KL Div: 3001.9622\n",
      "Epoch[3/15], Step [40/469], Reconst Loss: 12806.9912, KL Div: 3151.0852\n",
      "Epoch[3/15], Step [50/469], Reconst Loss: 11772.0244, KL Div: 2975.6797\n",
      "Epoch[3/15], Step [60/469], Reconst Loss: 12163.2998, KL Div: 3005.0713\n",
      "Epoch[3/15], Step [70/469], Reconst Loss: 11618.7676, KL Div: 3032.7505\n",
      "Epoch[3/15], Step [80/469], Reconst Loss: 11789.8320, KL Div: 3011.0835\n",
      "Epoch[3/15], Step [90/469], Reconst Loss: 11413.4629, KL Div: 2940.1907\n",
      "Epoch[3/15], Step [100/469], Reconst Loss: 12128.0527, KL Div: 3076.8271\n",
      "Epoch[3/15], Step [110/469], Reconst Loss: 11985.2842, KL Div: 3008.6426\n",
      "Epoch[3/15], Step [120/469], Reconst Loss: 11680.0840, KL Div: 3003.9773\n",
      "Epoch[3/15], Step [130/469], Reconst Loss: 11852.2422, KL Div: 2970.6025\n",
      "Epoch[3/15], Step [140/469], Reconst Loss: 11727.1416, KL Div: 2953.5903\n",
      "Epoch[3/15], Step [150/469], Reconst Loss: 11465.1211, KL Div: 3027.5291\n",
      "Epoch[3/15], Step [160/469], Reconst Loss: 11891.2295, KL Div: 3019.9575\n",
      "Epoch[3/15], Step [170/469], Reconst Loss: 11594.3193, KL Div: 3022.6099\n",
      "Epoch[3/15], Step [180/469], Reconst Loss: 11723.8018, KL Div: 3036.7212\n",
      "Epoch[3/15], Step [190/469], Reconst Loss: 10996.2324, KL Div: 3070.6169\n",
      "Epoch[3/15], Step [200/469], Reconst Loss: 11926.0283, KL Div: 3100.6665\n",
      "Epoch[3/15], Step [210/469], Reconst Loss: 11324.3691, KL Div: 3150.4165\n",
      "Epoch[3/15], Step [220/469], Reconst Loss: 11674.1660, KL Div: 2975.5671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3/15], Step [230/469], Reconst Loss: 11279.9180, KL Div: 3002.1382\n",
      "Epoch[3/15], Step [240/469], Reconst Loss: 11606.2031, KL Div: 3093.1689\n",
      "Epoch[3/15], Step [250/469], Reconst Loss: 11981.4688, KL Div: 3090.7104\n",
      "Epoch[3/15], Step [260/469], Reconst Loss: 11476.4658, KL Div: 2941.3228\n",
      "Epoch[3/15], Step [270/469], Reconst Loss: 12069.5498, KL Div: 3078.3970\n",
      "Epoch[3/15], Step [280/469], Reconst Loss: 11580.1650, KL Div: 3087.9292\n",
      "Epoch[3/15], Step [290/469], Reconst Loss: 10972.2070, KL Div: 2955.0886\n",
      "Epoch[3/15], Step [300/469], Reconst Loss: 11546.9355, KL Div: 3038.3921\n",
      "Epoch[3/15], Step [310/469], Reconst Loss: 11556.1738, KL Div: 3064.8076\n",
      "Epoch[3/15], Step [320/469], Reconst Loss: 11562.6875, KL Div: 2985.3674\n",
      "Epoch[3/15], Step [330/469], Reconst Loss: 11088.9941, KL Div: 3122.2715\n",
      "Epoch[3/15], Step [340/469], Reconst Loss: 11468.8711, KL Div: 2997.9771\n",
      "Epoch[3/15], Step [350/469], Reconst Loss: 11055.3965, KL Div: 2996.1033\n",
      "Epoch[3/15], Step [360/469], Reconst Loss: 11415.5078, KL Div: 3020.2842\n",
      "Epoch[3/15], Step [370/469], Reconst Loss: 11216.4570, KL Div: 3161.7729\n",
      "Epoch[3/15], Step [380/469], Reconst Loss: 11607.9414, KL Div: 2921.3965\n",
      "Epoch[3/15], Step [390/469], Reconst Loss: 11420.1943, KL Div: 3119.8118\n",
      "Epoch[3/15], Step [400/469], Reconst Loss: 11009.0840, KL Div: 2995.8152\n",
      "Epoch[3/15], Step [410/469], Reconst Loss: 11704.6826, KL Div: 3097.6824\n",
      "Epoch[3/15], Step [420/469], Reconst Loss: 11886.8223, KL Div: 3043.5579\n",
      "Epoch[3/15], Step [430/469], Reconst Loss: 11734.9277, KL Div: 3075.8296\n",
      "Epoch[3/15], Step [440/469], Reconst Loss: 10781.5430, KL Div: 3048.6128\n",
      "Epoch[3/15], Step [450/469], Reconst Loss: 11304.1816, KL Div: 3087.5049\n",
      "Epoch[3/15], Step [460/469], Reconst Loss: 11091.1924, KL Div: 3043.6987\n",
      "Epoch[4/15], Step [10/469], Reconst Loss: 11705.0781, KL Div: 3071.4607\n",
      "Epoch[4/15], Step [20/469], Reconst Loss: 10962.9150, KL Div: 3094.7085\n",
      "Epoch[4/15], Step [30/469], Reconst Loss: 10968.2734, KL Div: 3118.1919\n",
      "Epoch[4/15], Step [40/469], Reconst Loss: 11506.3652, KL Div: 3038.4531\n",
      "Epoch[4/15], Step [50/469], Reconst Loss: 11435.4834, KL Div: 3099.7903\n",
      "Epoch[4/15], Step [60/469], Reconst Loss: 11481.9141, KL Div: 3105.0737\n",
      "Epoch[4/15], Step [70/469], Reconst Loss: 11097.6074, KL Div: 3123.4675\n",
      "Epoch[4/15], Step [80/469], Reconst Loss: 11126.0117, KL Div: 3062.3054\n",
      "Epoch[4/15], Step [90/469], Reconst Loss: 11229.4346, KL Div: 3219.3032\n",
      "Epoch[4/15], Step [100/469], Reconst Loss: 11506.5859, KL Div: 3092.4248\n",
      "Epoch[4/15], Step [110/469], Reconst Loss: 11364.7119, KL Div: 3000.8955\n",
      "Epoch[4/15], Step [120/469], Reconst Loss: 11126.6045, KL Div: 3191.3311\n",
      "Epoch[4/15], Step [130/469], Reconst Loss: 11253.9375, KL Div: 3066.6011\n",
      "Epoch[4/15], Step [140/469], Reconst Loss: 11400.5127, KL Div: 3185.6382\n",
      "Epoch[4/15], Step [150/469], Reconst Loss: 10716.6631, KL Div: 3013.0454\n",
      "Epoch[4/15], Step [160/469], Reconst Loss: 10677.8037, KL Div: 3016.8203\n",
      "Epoch[4/15], Step [170/469], Reconst Loss: 11785.1631, KL Div: 3177.4189\n",
      "Epoch[4/15], Step [180/469], Reconst Loss: 11229.1689, KL Div: 3128.7283\n",
      "Epoch[4/15], Step [190/469], Reconst Loss: 11303.8213, KL Div: 3102.2236\n",
      "Epoch[4/15], Step [200/469], Reconst Loss: 10801.5420, KL Div: 3032.5327\n",
      "Epoch[4/15], Step [210/469], Reconst Loss: 10722.1104, KL Div: 3099.6646\n",
      "Epoch[4/15], Step [220/469], Reconst Loss: 11838.9326, KL Div: 3128.3110\n",
      "Epoch[4/15], Step [230/469], Reconst Loss: 11503.0625, KL Div: 3174.6372\n",
      "Epoch[4/15], Step [240/469], Reconst Loss: 11439.3877, KL Div: 3179.0510\n",
      "Epoch[4/15], Step [250/469], Reconst Loss: 10811.6514, KL Div: 3027.5601\n",
      "Epoch[4/15], Step [260/469], Reconst Loss: 11151.9482, KL Div: 3219.9448\n",
      "Epoch[4/15], Step [270/469], Reconst Loss: 10706.1143, KL Div: 3057.0649\n",
      "Epoch[4/15], Step [280/469], Reconst Loss: 11269.9600, KL Div: 3090.2600\n",
      "Epoch[4/15], Step [290/469], Reconst Loss: 10962.5342, KL Div: 3061.5032\n",
      "Epoch[4/15], Step [300/469], Reconst Loss: 10853.9551, KL Div: 3085.7959\n",
      "Epoch[4/15], Step [310/469], Reconst Loss: 11371.9531, KL Div: 3010.1721\n",
      "Epoch[4/15], Step [320/469], Reconst Loss: 10695.9990, KL Div: 3179.4607\n",
      "Epoch[4/15], Step [330/469], Reconst Loss: 11211.4375, KL Div: 3088.9116\n",
      "Epoch[4/15], Step [340/469], Reconst Loss: 11528.0840, KL Div: 3262.1104\n",
      "Epoch[4/15], Step [350/469], Reconst Loss: 11202.4375, KL Div: 3110.1211\n",
      "Epoch[4/15], Step [360/469], Reconst Loss: 10858.3721, KL Div: 3114.8237\n",
      "Epoch[4/15], Step [370/469], Reconst Loss: 10946.3887, KL Div: 3171.5154\n",
      "Epoch[4/15], Step [380/469], Reconst Loss: 11646.0352, KL Div: 3054.3154\n",
      "Epoch[4/15], Step [390/469], Reconst Loss: 11154.2998, KL Div: 3171.6743\n",
      "Epoch[4/15], Step [400/469], Reconst Loss: 10927.2334, KL Div: 3076.6096\n",
      "Epoch[4/15], Step [410/469], Reconst Loss: 10867.6572, KL Div: 3028.8059\n",
      "Epoch[4/15], Step [420/469], Reconst Loss: 10937.0059, KL Div: 3073.3105\n",
      "Epoch[4/15], Step [430/469], Reconst Loss: 10903.1377, KL Div: 3240.5801\n",
      "Epoch[4/15], Step [440/469], Reconst Loss: 11207.0059, KL Div: 3217.4985\n",
      "Epoch[4/15], Step [450/469], Reconst Loss: 10872.0625, KL Div: 3033.2378\n",
      "Epoch[4/15], Step [460/469], Reconst Loss: 10741.8301, KL Div: 3147.6306\n",
      "Epoch[5/15], Step [10/469], Reconst Loss: 10883.9346, KL Div: 3188.2097\n",
      "Epoch[5/15], Step [20/469], Reconst Loss: 10939.4834, KL Div: 3057.5703\n",
      "Epoch[5/15], Step [30/469], Reconst Loss: 10560.6934, KL Div: 3021.7183\n",
      "Epoch[5/15], Step [40/469], Reconst Loss: 11261.3623, KL Div: 3292.9707\n",
      "Epoch[5/15], Step [50/469], Reconst Loss: 11136.2109, KL Div: 3179.2998\n",
      "Epoch[5/15], Step [60/469], Reconst Loss: 10846.6797, KL Div: 3180.3643\n",
      "Epoch[5/15], Step [70/469], Reconst Loss: 11193.4590, KL Div: 3201.4976\n",
      "Epoch[5/15], Step [80/469], Reconst Loss: 10879.9580, KL Div: 3109.4221\n",
      "Epoch[5/15], Step [90/469], Reconst Loss: 10775.9131, KL Div: 3106.6348\n",
      "Epoch[5/15], Step [100/469], Reconst Loss: 11130.4365, KL Div: 3207.2002\n",
      "Epoch[5/15], Step [110/469], Reconst Loss: 10581.7812, KL Div: 3108.7585\n",
      "Epoch[5/15], Step [120/469], Reconst Loss: 11169.4902, KL Div: 3182.5034\n",
      "Epoch[5/15], Step [130/469], Reconst Loss: 11020.8271, KL Div: 3135.7437\n",
      "Epoch[5/15], Step [140/469], Reconst Loss: 11239.3311, KL Div: 3096.0110\n",
      "Epoch[5/15], Step [150/469], Reconst Loss: 11053.7461, KL Div: 3143.5459\n",
      "Epoch[5/15], Step [160/469], Reconst Loss: 10502.3564, KL Div: 3049.0044\n",
      "Epoch[5/15], Step [170/469], Reconst Loss: 11160.4873, KL Div: 3138.9629\n",
      "Epoch[5/15], Step [180/469], Reconst Loss: 11078.7451, KL Div: 3209.1587\n",
      "Epoch[5/15], Step [190/469], Reconst Loss: 11012.9248, KL Div: 3109.5591\n",
      "Epoch[5/15], Step [200/469], Reconst Loss: 10949.0352, KL Div: 3201.5251\n",
      "Epoch[5/15], Step [210/469], Reconst Loss: 10913.9355, KL Div: 3126.1040\n",
      "Epoch[5/15], Step [220/469], Reconst Loss: 10888.3398, KL Div: 3126.2275\n",
      "Epoch[5/15], Step [230/469], Reconst Loss: 10710.0947, KL Div: 3197.7236\n",
      "Epoch[5/15], Step [240/469], Reconst Loss: 11102.2246, KL Div: 3241.2109\n",
      "Epoch[5/15], Step [250/469], Reconst Loss: 11142.2744, KL Div: 3193.5393\n",
      "Epoch[5/15], Step [260/469], Reconst Loss: 10664.1748, KL Div: 3010.2031\n",
      "Epoch[5/15], Step [270/469], Reconst Loss: 10616.0303, KL Div: 3062.6938\n",
      "Epoch[5/15], Step [280/469], Reconst Loss: 11085.5342, KL Div: 3146.2173\n",
      "Epoch[5/15], Step [290/469], Reconst Loss: 11098.4092, KL Div: 3157.1104\n",
      "Epoch[5/15], Step [300/469], Reconst Loss: 10247.7568, KL Div: 3115.5435\n",
      "Epoch[5/15], Step [310/469], Reconst Loss: 11470.3174, KL Div: 3243.0054\n",
      "Epoch[5/15], Step [320/469], Reconst Loss: 10951.8193, KL Div: 3187.9512\n",
      "Epoch[5/15], Step [330/469], Reconst Loss: 11101.9023, KL Div: 3147.7478\n",
      "Epoch[5/15], Step [340/469], Reconst Loss: 10707.6973, KL Div: 3147.8604\n",
      "Epoch[5/15], Step [350/469], Reconst Loss: 10950.9707, KL Div: 3218.0303\n",
      "Epoch[5/15], Step [360/469], Reconst Loss: 10951.6318, KL Div: 3137.3806\n",
      "Epoch[5/15], Step [370/469], Reconst Loss: 10563.7764, KL Div: 3171.1887\n",
      "Epoch[5/15], Step [380/469], Reconst Loss: 11041.0586, KL Div: 3165.6506\n",
      "Epoch[5/15], Step [390/469], Reconst Loss: 10823.8613, KL Div: 3235.2920\n",
      "Epoch[5/15], Step [400/469], Reconst Loss: 10687.2100, KL Div: 3071.7803\n",
      "Epoch[5/15], Step [410/469], Reconst Loss: 10644.2256, KL Div: 3195.8428\n",
      "Epoch[5/15], Step [420/469], Reconst Loss: 11109.7412, KL Div: 3234.9255\n",
      "Epoch[5/15], Step [430/469], Reconst Loss: 10739.0176, KL Div: 3160.1357\n",
      "Epoch[5/15], Step [440/469], Reconst Loss: 10860.6660, KL Div: 3154.1958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5/15], Step [450/469], Reconst Loss: 10619.1807, KL Div: 3135.7598\n",
      "Epoch[5/15], Step [460/469], Reconst Loss: 10797.3545, KL Div: 3223.0081\n",
      "Epoch[6/15], Step [10/469], Reconst Loss: 10805.0762, KL Div: 3162.7700\n",
      "Epoch[6/15], Step [20/469], Reconst Loss: 10878.7236, KL Div: 3159.0806\n",
      "Epoch[6/15], Step [30/469], Reconst Loss: 10550.5391, KL Div: 3207.9429\n",
      "Epoch[6/15], Step [40/469], Reconst Loss: 10705.5518, KL Div: 3133.4788\n",
      "Epoch[6/15], Step [50/469], Reconst Loss: 11107.6299, KL Div: 3274.9458\n",
      "Epoch[6/15], Step [60/469], Reconst Loss: 11031.3066, KL Div: 3146.7227\n",
      "Epoch[6/15], Step [70/469], Reconst Loss: 10435.3945, KL Div: 3208.8533\n",
      "Epoch[6/15], Step [80/469], Reconst Loss: 10447.3145, KL Div: 3202.1809\n",
      "Epoch[6/15], Step [90/469], Reconst Loss: 10789.8945, KL Div: 3160.6426\n",
      "Epoch[6/15], Step [100/469], Reconst Loss: 11026.4961, KL Div: 3288.9580\n",
      "Epoch[6/15], Step [110/469], Reconst Loss: 11043.3867, KL Div: 3132.1416\n",
      "Epoch[6/15], Step [120/469], Reconst Loss: 10731.0723, KL Div: 3248.3364\n",
      "Epoch[6/15], Step [130/469], Reconst Loss: 10526.1621, KL Div: 3082.0083\n",
      "Epoch[6/15], Step [140/469], Reconst Loss: 10328.2578, KL Div: 3228.7070\n",
      "Epoch[6/15], Step [150/469], Reconst Loss: 11190.0869, KL Div: 3239.4612\n",
      "Epoch[6/15], Step [160/469], Reconst Loss: 11125.8760, KL Div: 3241.1855\n",
      "Epoch[6/15], Step [170/469], Reconst Loss: 10747.6484, KL Div: 3180.8994\n",
      "Epoch[6/15], Step [180/469], Reconst Loss: 10458.8906, KL Div: 3111.4282\n",
      "Epoch[6/15], Step [190/469], Reconst Loss: 10748.7080, KL Div: 3211.9456\n",
      "Epoch[6/15], Step [200/469], Reconst Loss: 10776.6143, KL Div: 3065.6201\n",
      "Epoch[6/15], Step [210/469], Reconst Loss: 10594.0625, KL Div: 3212.8191\n",
      "Epoch[6/15], Step [220/469], Reconst Loss: 10605.0850, KL Div: 3106.9854\n",
      "Epoch[6/15], Step [230/469], Reconst Loss: 10129.6045, KL Div: 3123.8181\n",
      "Epoch[6/15], Step [240/469], Reconst Loss: 10806.2852, KL Div: 3211.9031\n",
      "Epoch[6/15], Step [250/469], Reconst Loss: 10812.8350, KL Div: 3205.5674\n",
      "Epoch[6/15], Step [260/469], Reconst Loss: 10519.8242, KL Div: 3265.0176\n",
      "Epoch[6/15], Step [270/469], Reconst Loss: 10535.0439, KL Div: 3087.1921\n",
      "Epoch[6/15], Step [280/469], Reconst Loss: 11065.3975, KL Div: 3208.5994\n",
      "Epoch[6/15], Step [290/469], Reconst Loss: 11380.3350, KL Div: 3320.3040\n",
      "Epoch[6/15], Step [300/469], Reconst Loss: 10453.6992, KL Div: 3075.2202\n",
      "Epoch[6/15], Step [310/469], Reconst Loss: 10535.9199, KL Div: 3161.5977\n",
      "Epoch[6/15], Step [320/469], Reconst Loss: 11171.3125, KL Div: 3277.3613\n",
      "Epoch[6/15], Step [330/469], Reconst Loss: 10818.0264, KL Div: 3073.2930\n",
      "Epoch[6/15], Step [340/469], Reconst Loss: 10869.3936, KL Div: 3295.8716\n",
      "Epoch[6/15], Step [350/469], Reconst Loss: 10922.8711, KL Div: 3082.1392\n",
      "Epoch[6/15], Step [360/469], Reconst Loss: 10574.8516, KL Div: 3123.9231\n",
      "Epoch[6/15], Step [370/469], Reconst Loss: 10066.2168, KL Div: 3159.0371\n",
      "Epoch[6/15], Step [380/469], Reconst Loss: 10527.6973, KL Div: 3162.7761\n",
      "Epoch[6/15], Step [390/469], Reconst Loss: 10589.8330, KL Div: 3121.2256\n",
      "Epoch[6/15], Step [400/469], Reconst Loss: 10809.6680, KL Div: 3219.1970\n",
      "Epoch[6/15], Step [410/469], Reconst Loss: 10940.6309, KL Div: 3196.3911\n",
      "Epoch[6/15], Step [420/469], Reconst Loss: 10406.1768, KL Div: 3176.5833\n",
      "Epoch[6/15], Step [430/469], Reconst Loss: 10740.7578, KL Div: 3196.8643\n",
      "Epoch[6/15], Step [440/469], Reconst Loss: 10478.2695, KL Div: 3202.9231\n",
      "Epoch[6/15], Step [450/469], Reconst Loss: 10662.5107, KL Div: 3124.4678\n",
      "Epoch[6/15], Step [460/469], Reconst Loss: 10294.7432, KL Div: 3157.5249\n",
      "Epoch[7/15], Step [10/469], Reconst Loss: 10810.8477, KL Div: 3135.1313\n",
      "Epoch[7/15], Step [20/469], Reconst Loss: 10867.3105, KL Div: 3223.1790\n",
      "Epoch[7/15], Step [30/469], Reconst Loss: 10642.4922, KL Div: 3290.8740\n",
      "Epoch[7/15], Step [40/469], Reconst Loss: 10406.4346, KL Div: 3157.9084\n",
      "Epoch[7/15], Step [50/469], Reconst Loss: 11008.2773, KL Div: 3213.3691\n",
      "Epoch[7/15], Step [60/469], Reconst Loss: 10387.3213, KL Div: 3085.0322\n",
      "Epoch[7/15], Step [70/469], Reconst Loss: 10706.2549, KL Div: 3152.7358\n",
      "Epoch[7/15], Step [80/469], Reconst Loss: 9948.3975, KL Div: 3067.1025\n",
      "Epoch[7/15], Step [90/469], Reconst Loss: 10406.8174, KL Div: 3047.6660\n",
      "Epoch[7/15], Step [100/469], Reconst Loss: 10818.0527, KL Div: 3161.7056\n",
      "Epoch[7/15], Step [110/469], Reconst Loss: 10447.5527, KL Div: 3158.3091\n",
      "Epoch[7/15], Step [120/469], Reconst Loss: 10013.7070, KL Div: 3047.8811\n",
      "Epoch[7/15], Step [130/469], Reconst Loss: 10576.4561, KL Div: 3171.6172\n",
      "Epoch[7/15], Step [140/469], Reconst Loss: 10491.3750, KL Div: 3320.7566\n",
      "Epoch[7/15], Step [150/469], Reconst Loss: 10608.3145, KL Div: 3161.3718\n",
      "Epoch[7/15], Step [160/469], Reconst Loss: 10491.2744, KL Div: 3119.9082\n",
      "Epoch[7/15], Step [170/469], Reconst Loss: 10363.9238, KL Div: 3268.2429\n",
      "Epoch[7/15], Step [180/469], Reconst Loss: 10733.1914, KL Div: 3174.6899\n",
      "Epoch[7/15], Step [190/469], Reconst Loss: 10738.7344, KL Div: 3215.7505\n",
      "Epoch[7/15], Step [200/469], Reconst Loss: 10615.6074, KL Div: 3188.4492\n",
      "Epoch[7/15], Step [210/469], Reconst Loss: 10325.4277, KL Div: 3034.9521\n",
      "Epoch[7/15], Step [220/469], Reconst Loss: 10791.4326, KL Div: 3234.6785\n",
      "Epoch[7/15], Step [230/469], Reconst Loss: 10704.6348, KL Div: 3167.3311\n",
      "Epoch[7/15], Step [240/469], Reconst Loss: 10754.8438, KL Div: 3150.4102\n",
      "Epoch[7/15], Step [250/469], Reconst Loss: 10350.4375, KL Div: 3166.2678\n",
      "Epoch[7/15], Step [260/469], Reconst Loss: 10552.8223, KL Div: 3130.7559\n",
      "Epoch[7/15], Step [270/469], Reconst Loss: 10328.9824, KL Div: 3239.9304\n",
      "Epoch[7/15], Step [280/469], Reconst Loss: 10360.6465, KL Div: 3200.1411\n",
      "Epoch[7/15], Step [290/469], Reconst Loss: 10320.7158, KL Div: 3067.8206\n",
      "Epoch[7/15], Step [300/469], Reconst Loss: 10943.6504, KL Div: 3259.3931\n",
      "Epoch[7/15], Step [310/469], Reconst Loss: 10938.2441, KL Div: 3188.0840\n",
      "Epoch[7/15], Step [320/469], Reconst Loss: 11017.9824, KL Div: 3186.4668\n",
      "Epoch[7/15], Step [330/469], Reconst Loss: 10730.8203, KL Div: 3194.8591\n",
      "Epoch[7/15], Step [340/469], Reconst Loss: 10610.3057, KL Div: 3103.5913\n",
      "Epoch[7/15], Step [350/469], Reconst Loss: 10803.4365, KL Div: 3188.4487\n",
      "Epoch[7/15], Step [360/469], Reconst Loss: 11085.0430, KL Div: 3246.7334\n",
      "Epoch[7/15], Step [370/469], Reconst Loss: 10382.2910, KL Div: 3216.3589\n",
      "Epoch[7/15], Step [380/469], Reconst Loss: 11138.9766, KL Div: 3183.3223\n",
      "Epoch[7/15], Step [390/469], Reconst Loss: 10431.8633, KL Div: 3124.6167\n",
      "Epoch[7/15], Step [400/469], Reconst Loss: 10679.3584, KL Div: 3206.1321\n",
      "Epoch[7/15], Step [410/469], Reconst Loss: 10420.7148, KL Div: 3124.2520\n",
      "Epoch[7/15], Step [420/469], Reconst Loss: 10336.0430, KL Div: 3231.3396\n",
      "Epoch[7/15], Step [430/469], Reconst Loss: 10711.2295, KL Div: 3133.9053\n",
      "Epoch[7/15], Step [440/469], Reconst Loss: 10551.0146, KL Div: 3283.7927\n",
      "Epoch[7/15], Step [450/469], Reconst Loss: 10822.9365, KL Div: 3108.6455\n",
      "Epoch[7/15], Step [460/469], Reconst Loss: 10833.5273, KL Div: 3229.1294\n",
      "Epoch[8/15], Step [10/469], Reconst Loss: 10676.5645, KL Div: 3101.0371\n",
      "Epoch[8/15], Step [20/469], Reconst Loss: 10385.3848, KL Div: 3325.3496\n",
      "Epoch[8/15], Step [30/469], Reconst Loss: 10647.4492, KL Div: 3200.4719\n",
      "Epoch[8/15], Step [40/469], Reconst Loss: 10030.8750, KL Div: 3126.7095\n",
      "Epoch[8/15], Step [50/469], Reconst Loss: 10981.3730, KL Div: 3377.2129\n",
      "Epoch[8/15], Step [60/469], Reconst Loss: 10197.5020, KL Div: 3118.0112\n",
      "Epoch[8/15], Step [70/469], Reconst Loss: 10681.7578, KL Div: 3255.0239\n",
      "Epoch[8/15], Step [80/469], Reconst Loss: 10306.1016, KL Div: 3224.2253\n",
      "Epoch[8/15], Step [90/469], Reconst Loss: 10153.1133, KL Div: 3092.7544\n",
      "Epoch[8/15], Step [100/469], Reconst Loss: 10686.8984, KL Div: 3244.3237\n",
      "Epoch[8/15], Step [110/469], Reconst Loss: 10182.3789, KL Div: 3210.1694\n",
      "Epoch[8/15], Step [120/469], Reconst Loss: 10428.8906, KL Div: 3168.2117\n",
      "Epoch[8/15], Step [130/469], Reconst Loss: 10257.5293, KL Div: 3133.4104\n",
      "Epoch[8/15], Step [140/469], Reconst Loss: 10270.7686, KL Div: 3234.1951\n",
      "Epoch[8/15], Step [150/469], Reconst Loss: 9840.6367, KL Div: 3116.8579\n",
      "Epoch[8/15], Step [160/469], Reconst Loss: 10092.8535, KL Div: 3121.7961\n",
      "Epoch[8/15], Step [170/469], Reconst Loss: 10465.9131, KL Div: 3274.8547\n",
      "Epoch[8/15], Step [180/469], Reconst Loss: 10171.4619, KL Div: 3099.1084\n",
      "Epoch[8/15], Step [190/469], Reconst Loss: 10621.8643, KL Div: 3266.4390\n",
      "Epoch[8/15], Step [200/469], Reconst Loss: 10512.0322, KL Div: 3147.3484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[8/15], Step [210/469], Reconst Loss: 10664.0117, KL Div: 3261.8735\n",
      "Epoch[8/15], Step [220/469], Reconst Loss: 10387.2061, KL Div: 3230.9878\n",
      "Epoch[8/15], Step [230/469], Reconst Loss: 10220.1230, KL Div: 3195.6631\n",
      "Epoch[8/15], Step [240/469], Reconst Loss: 10307.7383, KL Div: 3203.2595\n",
      "Epoch[8/15], Step [250/469], Reconst Loss: 10721.4121, KL Div: 3159.6187\n",
      "Epoch[8/15], Step [260/469], Reconst Loss: 10975.5811, KL Div: 3300.1047\n",
      "Epoch[8/15], Step [270/469], Reconst Loss: 10979.5918, KL Div: 3200.2361\n",
      "Epoch[8/15], Step [280/469], Reconst Loss: 10162.4404, KL Div: 3266.4167\n",
      "Epoch[8/15], Step [290/469], Reconst Loss: 10668.8535, KL Div: 3172.8291\n",
      "Epoch[8/15], Step [300/469], Reconst Loss: 10727.4775, KL Div: 3179.8770\n",
      "Epoch[8/15], Step [310/469], Reconst Loss: 9937.4141, KL Div: 3170.7656\n",
      "Epoch[8/15], Step [320/469], Reconst Loss: 10399.9785, KL Div: 3118.6182\n",
      "Epoch[8/15], Step [330/469], Reconst Loss: 10000.6045, KL Div: 3110.5415\n",
      "Epoch[8/15], Step [340/469], Reconst Loss: 10497.9307, KL Div: 3098.4673\n",
      "Epoch[8/15], Step [350/469], Reconst Loss: 11142.5410, KL Div: 3170.4463\n",
      "Epoch[8/15], Step [360/469], Reconst Loss: 10642.2725, KL Div: 3244.8237\n",
      "Epoch[8/15], Step [370/469], Reconst Loss: 10254.6289, KL Div: 3197.7827\n",
      "Epoch[8/15], Step [380/469], Reconst Loss: 10449.0127, KL Div: 3249.6812\n",
      "Epoch[8/15], Step [390/469], Reconst Loss: 10821.9795, KL Div: 3230.0427\n",
      "Epoch[8/15], Step [400/469], Reconst Loss: 10422.9346, KL Div: 3194.2461\n",
      "Epoch[8/15], Step [410/469], Reconst Loss: 10508.2207, KL Div: 3152.5044\n",
      "Epoch[8/15], Step [420/469], Reconst Loss: 10863.3877, KL Div: 3176.4561\n",
      "Epoch[8/15], Step [430/469], Reconst Loss: 10503.0566, KL Div: 3151.0305\n",
      "Epoch[8/15], Step [440/469], Reconst Loss: 10543.6074, KL Div: 3234.5845\n",
      "Epoch[8/15], Step [450/469], Reconst Loss: 10391.4893, KL Div: 3107.7610\n",
      "Epoch[8/15], Step [460/469], Reconst Loss: 10531.7832, KL Div: 3251.7161\n",
      "Epoch[9/15], Step [10/469], Reconst Loss: 10362.2109, KL Div: 3213.3799\n",
      "Epoch[9/15], Step [20/469], Reconst Loss: 10818.1406, KL Div: 3270.1343\n",
      "Epoch[9/15], Step [30/469], Reconst Loss: 10288.2959, KL Div: 3236.1531\n",
      "Epoch[9/15], Step [40/469], Reconst Loss: 10561.6074, KL Div: 3186.3215\n",
      "Epoch[9/15], Step [50/469], Reconst Loss: 10579.9893, KL Div: 3207.5903\n",
      "Epoch[9/15], Step [60/469], Reconst Loss: 10265.9814, KL Div: 3135.8506\n",
      "Epoch[9/15], Step [70/469], Reconst Loss: 10290.1729, KL Div: 3238.0684\n",
      "Epoch[9/15], Step [80/469], Reconst Loss: 10372.6973, KL Div: 3178.8525\n",
      "Epoch[9/15], Step [90/469], Reconst Loss: 10485.8340, KL Div: 3162.7754\n",
      "Epoch[9/15], Step [100/469], Reconst Loss: 10606.1084, KL Div: 3238.0486\n",
      "Epoch[9/15], Step [110/469], Reconst Loss: 10358.4502, KL Div: 3116.4436\n",
      "Epoch[9/15], Step [120/469], Reconst Loss: 10547.4453, KL Div: 3086.5295\n",
      "Epoch[9/15], Step [130/469], Reconst Loss: 10637.5811, KL Div: 3234.0740\n",
      "Epoch[9/15], Step [140/469], Reconst Loss: 10421.5469, KL Div: 3315.3018\n",
      "Epoch[9/15], Step [150/469], Reconst Loss: 10565.7979, KL Div: 3209.1729\n",
      "Epoch[9/15], Step [160/469], Reconst Loss: 10076.0742, KL Div: 3164.5254\n",
      "Epoch[9/15], Step [170/469], Reconst Loss: 10470.2881, KL Div: 3197.1252\n",
      "Epoch[9/15], Step [180/469], Reconst Loss: 10620.3379, KL Div: 3255.5693\n",
      "Epoch[9/15], Step [190/469], Reconst Loss: 10225.1035, KL Div: 3265.3860\n",
      "Epoch[9/15], Step [200/469], Reconst Loss: 10745.4316, KL Div: 3194.1399\n",
      "Epoch[9/15], Step [210/469], Reconst Loss: 10370.8672, KL Div: 3232.2239\n",
      "Epoch[9/15], Step [220/469], Reconst Loss: 10713.2334, KL Div: 3288.5168\n",
      "Epoch[9/15], Step [230/469], Reconst Loss: 9980.6074, KL Div: 3117.2656\n",
      "Epoch[9/15], Step [240/469], Reconst Loss: 10334.6367, KL Div: 3266.2366\n",
      "Epoch[9/15], Step [250/469], Reconst Loss: 10137.2100, KL Div: 3192.9136\n",
      "Epoch[9/15], Step [260/469], Reconst Loss: 10118.2266, KL Div: 3170.1904\n",
      "Epoch[9/15], Step [270/469], Reconst Loss: 9968.6250, KL Div: 3180.9116\n",
      "Epoch[9/15], Step [280/469], Reconst Loss: 10367.6699, KL Div: 3213.4531\n",
      "Epoch[9/15], Step [290/469], Reconst Loss: 10084.5459, KL Div: 3152.3389\n",
      "Epoch[9/15], Step [300/469], Reconst Loss: 10406.8223, KL Div: 3221.5569\n",
      "Epoch[9/15], Step [310/469], Reconst Loss: 10148.7988, KL Div: 3145.7490\n",
      "Epoch[9/15], Step [320/469], Reconst Loss: 10083.5820, KL Div: 3215.8000\n",
      "Epoch[9/15], Step [330/469], Reconst Loss: 10604.6055, KL Div: 3231.3689\n",
      "Epoch[9/15], Step [340/469], Reconst Loss: 10244.0420, KL Div: 3117.5146\n",
      "Epoch[9/15], Step [350/469], Reconst Loss: 10421.4316, KL Div: 3245.8794\n",
      "Epoch[9/15], Step [360/469], Reconst Loss: 10676.5547, KL Div: 3180.9802\n",
      "Epoch[9/15], Step [370/469], Reconst Loss: 10391.0879, KL Div: 3158.1882\n",
      "Epoch[9/15], Step [380/469], Reconst Loss: 10460.7725, KL Div: 3278.2354\n",
      "Epoch[9/15], Step [390/469], Reconst Loss: 10541.6152, KL Div: 3173.4675\n",
      "Epoch[9/15], Step [400/469], Reconst Loss: 10724.2432, KL Div: 3221.3792\n",
      "Epoch[9/15], Step [410/469], Reconst Loss: 10189.6504, KL Div: 3144.3938\n",
      "Epoch[9/15], Step [420/469], Reconst Loss: 10724.4561, KL Div: 3162.7866\n",
      "Epoch[9/15], Step [430/469], Reconst Loss: 9954.5273, KL Div: 3186.9583\n",
      "Epoch[9/15], Step [440/469], Reconst Loss: 10798.3809, KL Div: 3272.8008\n",
      "Epoch[9/15], Step [450/469], Reconst Loss: 10365.7578, KL Div: 3213.8230\n",
      "Epoch[9/15], Step [460/469], Reconst Loss: 10629.0977, KL Div: 3190.0122\n",
      "Epoch[10/15], Step [10/469], Reconst Loss: 10176.2695, KL Div: 3148.8276\n",
      "Epoch[10/15], Step [20/469], Reconst Loss: 10270.1338, KL Div: 3182.7722\n",
      "Epoch[10/15], Step [30/469], Reconst Loss: 10664.3047, KL Div: 3213.7864\n",
      "Epoch[10/15], Step [40/469], Reconst Loss: 9994.9404, KL Div: 3206.4341\n",
      "Epoch[10/15], Step [50/469], Reconst Loss: 10749.9219, KL Div: 3213.3948\n",
      "Epoch[10/15], Step [60/469], Reconst Loss: 10197.4951, KL Div: 3143.6621\n",
      "Epoch[10/15], Step [70/469], Reconst Loss: 10371.6455, KL Div: 3186.2559\n",
      "Epoch[10/15], Step [80/469], Reconst Loss: 10555.8145, KL Div: 3280.3147\n",
      "Epoch[10/15], Step [90/469], Reconst Loss: 10284.9658, KL Div: 3121.6113\n",
      "Epoch[10/15], Step [100/469], Reconst Loss: 10273.9971, KL Div: 3288.5786\n",
      "Epoch[10/15], Step [110/469], Reconst Loss: 10621.7842, KL Div: 3197.7849\n",
      "Epoch[10/15], Step [120/469], Reconst Loss: 10089.7695, KL Div: 3248.4185\n",
      "Epoch[10/15], Step [130/469], Reconst Loss: 10575.8809, KL Div: 3178.6885\n",
      "Epoch[10/15], Step [140/469], Reconst Loss: 10251.7246, KL Div: 3171.0234\n",
      "Epoch[10/15], Step [150/469], Reconst Loss: 10690.9941, KL Div: 3341.4985\n",
      "Epoch[10/15], Step [160/469], Reconst Loss: 10771.3340, KL Div: 3295.0002\n",
      "Epoch[10/15], Step [170/469], Reconst Loss: 10103.0459, KL Div: 3183.4526\n",
      "Epoch[10/15], Step [180/469], Reconst Loss: 10283.7529, KL Div: 3185.5564\n",
      "Epoch[10/15], Step [190/469], Reconst Loss: 10118.4443, KL Div: 3160.5298\n",
      "Epoch[10/15], Step [200/469], Reconst Loss: 10614.3604, KL Div: 3241.3145\n",
      "Epoch[10/15], Step [210/469], Reconst Loss: 10453.6279, KL Div: 3196.8589\n",
      "Epoch[10/15], Step [220/469], Reconst Loss: 10282.3477, KL Div: 3235.5718\n",
      "Epoch[10/15], Step [230/469], Reconst Loss: 10550.4922, KL Div: 3316.7844\n",
      "Epoch[10/15], Step [240/469], Reconst Loss: 9986.9512, KL Div: 3150.3037\n",
      "Epoch[10/15], Step [250/469], Reconst Loss: 10332.9443, KL Div: 3254.1589\n",
      "Epoch[10/15], Step [260/469], Reconst Loss: 10172.3877, KL Div: 3219.1279\n",
      "Epoch[10/15], Step [270/469], Reconst Loss: 10065.9883, KL Div: 3106.7163\n",
      "Epoch[10/15], Step [280/469], Reconst Loss: 10497.8223, KL Div: 3291.4253\n",
      "Epoch[10/15], Step [290/469], Reconst Loss: 10365.5068, KL Div: 3169.1819\n",
      "Epoch[10/15], Step [300/469], Reconst Loss: 10496.7520, KL Div: 3306.3792\n",
      "Epoch[10/15], Step [310/469], Reconst Loss: 10617.4893, KL Div: 3287.5383\n",
      "Epoch[10/15], Step [320/469], Reconst Loss: 10095.4678, KL Div: 3170.2734\n",
      "Epoch[10/15], Step [330/469], Reconst Loss: 9945.1514, KL Div: 3167.4458\n",
      "Epoch[10/15], Step [340/469], Reconst Loss: 10475.7705, KL Div: 3178.6904\n",
      "Epoch[10/15], Step [350/469], Reconst Loss: 10342.6318, KL Div: 3198.6460\n",
      "Epoch[10/15], Step [360/469], Reconst Loss: 10595.6768, KL Div: 3180.2236\n",
      "Epoch[10/15], Step [370/469], Reconst Loss: 10112.6680, KL Div: 3159.7095\n",
      "Epoch[10/15], Step [380/469], Reconst Loss: 10769.4854, KL Div: 3147.9551\n",
      "Epoch[10/15], Step [390/469], Reconst Loss: 9706.1504, KL Div: 3108.0178\n",
      "Epoch[10/15], Step [400/469], Reconst Loss: 10234.1592, KL Div: 3235.2549\n",
      "Epoch[10/15], Step [410/469], Reconst Loss: 9937.5449, KL Div: 3118.6406\n",
      "Epoch[10/15], Step [420/469], Reconst Loss: 10388.8398, KL Div: 3204.4873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/15], Step [430/469], Reconst Loss: 10263.3486, KL Div: 3211.5078\n",
      "Epoch[10/15], Step [440/469], Reconst Loss: 10342.8867, KL Div: 3235.4329\n",
      "Epoch[10/15], Step [450/469], Reconst Loss: 10609.6875, KL Div: 3237.0791\n",
      "Epoch[10/15], Step [460/469], Reconst Loss: 10561.2773, KL Div: 3242.2583\n",
      "Epoch[11/15], Step [10/469], Reconst Loss: 10465.3398, KL Div: 3080.9346\n",
      "Epoch[11/15], Step [20/469], Reconst Loss: 10313.2129, KL Div: 3205.6494\n",
      "Epoch[11/15], Step [30/469], Reconst Loss: 9985.9395, KL Div: 3269.6357\n",
      "Epoch[11/15], Step [40/469], Reconst Loss: 9809.3301, KL Div: 3132.9868\n",
      "Epoch[11/15], Step [50/469], Reconst Loss: 10396.8066, KL Div: 3317.9473\n",
      "Epoch[11/15], Step [60/469], Reconst Loss: 10358.9600, KL Div: 3163.3726\n",
      "Epoch[11/15], Step [70/469], Reconst Loss: 10704.8564, KL Div: 3317.0610\n",
      "Epoch[11/15], Step [80/469], Reconst Loss: 9845.1963, KL Div: 3207.2957\n",
      "Epoch[11/15], Step [90/469], Reconst Loss: 10249.4248, KL Div: 3152.3257\n",
      "Epoch[11/15], Step [100/469], Reconst Loss: 10159.0547, KL Div: 3186.5376\n",
      "Epoch[11/15], Step [110/469], Reconst Loss: 9931.8682, KL Div: 3147.5774\n",
      "Epoch[11/15], Step [120/469], Reconst Loss: 10146.4004, KL Div: 3159.2876\n",
      "Epoch[11/15], Step [130/469], Reconst Loss: 10045.2266, KL Div: 3276.1157\n",
      "Epoch[11/15], Step [140/469], Reconst Loss: 9946.3506, KL Div: 3146.4976\n",
      "Epoch[11/15], Step [150/469], Reconst Loss: 10324.1816, KL Div: 3121.2271\n",
      "Epoch[11/15], Step [160/469], Reconst Loss: 10506.9414, KL Div: 3249.2866\n",
      "Epoch[11/15], Step [170/469], Reconst Loss: 10172.5293, KL Div: 3229.4172\n",
      "Epoch[11/15], Step [180/469], Reconst Loss: 10501.3096, KL Div: 3209.3867\n",
      "Epoch[11/15], Step [190/469], Reconst Loss: 10313.9746, KL Div: 3291.2637\n",
      "Epoch[11/15], Step [200/469], Reconst Loss: 10191.0918, KL Div: 3233.0771\n",
      "Epoch[11/15], Step [210/469], Reconst Loss: 10455.3066, KL Div: 3264.4377\n",
      "Epoch[11/15], Step [220/469], Reconst Loss: 10144.7041, KL Div: 3195.8755\n",
      "Epoch[11/15], Step [230/469], Reconst Loss: 10674.9727, KL Div: 3278.9443\n",
      "Epoch[11/15], Step [240/469], Reconst Loss: 10178.3574, KL Div: 3306.2458\n",
      "Epoch[11/15], Step [250/469], Reconst Loss: 10499.0859, KL Div: 3199.5269\n",
      "Epoch[11/15], Step [260/469], Reconst Loss: 9988.7432, KL Div: 3202.4165\n",
      "Epoch[11/15], Step [270/469], Reconst Loss: 10579.0859, KL Div: 3297.1772\n",
      "Epoch[11/15], Step [280/469], Reconst Loss: 10284.1807, KL Div: 3198.9734\n",
      "Epoch[11/15], Step [290/469], Reconst Loss: 10306.1836, KL Div: 3314.9739\n",
      "Epoch[11/15], Step [300/469], Reconst Loss: 10414.2100, KL Div: 3191.9124\n",
      "Epoch[11/15], Step [310/469], Reconst Loss: 10255.6201, KL Div: 3245.9160\n",
      "Epoch[11/15], Step [320/469], Reconst Loss: 10348.9111, KL Div: 3228.2944\n",
      "Epoch[11/15], Step [330/469], Reconst Loss: 10166.6611, KL Div: 3193.0259\n",
      "Epoch[11/15], Step [340/469], Reconst Loss: 10595.2666, KL Div: 3294.0039\n",
      "Epoch[11/15], Step [350/469], Reconst Loss: 10287.4180, KL Div: 3268.3472\n",
      "Epoch[11/15], Step [360/469], Reconst Loss: 10465.4238, KL Div: 3183.0903\n",
      "Epoch[11/15], Step [370/469], Reconst Loss: 10323.6729, KL Div: 3335.6687\n",
      "Epoch[11/15], Step [380/469], Reconst Loss: 10385.0674, KL Div: 3246.0215\n",
      "Epoch[11/15], Step [390/469], Reconst Loss: 10059.8809, KL Div: 3149.1987\n",
      "Epoch[11/15], Step [400/469], Reconst Loss: 10450.6670, KL Div: 3269.3184\n",
      "Epoch[11/15], Step [410/469], Reconst Loss: 10687.1582, KL Div: 3265.7664\n",
      "Epoch[11/15], Step [420/469], Reconst Loss: 10260.6348, KL Div: 3098.5652\n",
      "Epoch[11/15], Step [430/469], Reconst Loss: 10534.7637, KL Div: 3316.0247\n",
      "Epoch[11/15], Step [440/469], Reconst Loss: 9921.9902, KL Div: 3181.8560\n",
      "Epoch[11/15], Step [450/469], Reconst Loss: 9921.3359, KL Div: 3160.1138\n",
      "Epoch[11/15], Step [460/469], Reconst Loss: 10363.0547, KL Div: 3260.2158\n",
      "Epoch[12/15], Step [10/469], Reconst Loss: 10312.7188, KL Div: 3196.2112\n",
      "Epoch[12/15], Step [20/469], Reconst Loss: 10325.5928, KL Div: 3247.0425\n",
      "Epoch[12/15], Step [30/469], Reconst Loss: 10806.7656, KL Div: 3252.0601\n",
      "Epoch[12/15], Step [40/469], Reconst Loss: 10513.5205, KL Div: 3281.9900\n",
      "Epoch[12/15], Step [50/469], Reconst Loss: 10254.1553, KL Div: 3239.8240\n",
      "Epoch[12/15], Step [60/469], Reconst Loss: 10501.4961, KL Div: 3218.8833\n",
      "Epoch[12/15], Step [70/469], Reconst Loss: 10398.2021, KL Div: 3146.8157\n",
      "Epoch[12/15], Step [80/469], Reconst Loss: 9571.0449, KL Div: 3198.8755\n",
      "Epoch[12/15], Step [90/469], Reconst Loss: 9957.4531, KL Div: 3194.6611\n",
      "Epoch[12/15], Step [100/469], Reconst Loss: 10214.6416, KL Div: 3116.5754\n",
      "Epoch[12/15], Step [110/469], Reconst Loss: 10740.2383, KL Div: 3236.2542\n",
      "Epoch[12/15], Step [120/469], Reconst Loss: 10436.0459, KL Div: 3390.2229\n",
      "Epoch[12/15], Step [130/469], Reconst Loss: 10644.0605, KL Div: 3269.5498\n",
      "Epoch[12/15], Step [140/469], Reconst Loss: 10115.7598, KL Div: 3161.0044\n",
      "Epoch[12/15], Step [150/469], Reconst Loss: 9824.8535, KL Div: 3327.0366\n",
      "Epoch[12/15], Step [160/469], Reconst Loss: 9819.2373, KL Div: 3285.7207\n",
      "Epoch[12/15], Step [170/469], Reconst Loss: 10038.2441, KL Div: 3080.1729\n",
      "Epoch[12/15], Step [180/469], Reconst Loss: 10424.5156, KL Div: 3391.6982\n",
      "Epoch[12/15], Step [190/469], Reconst Loss: 10079.4082, KL Div: 3184.8779\n",
      "Epoch[12/15], Step [200/469], Reconst Loss: 10693.4766, KL Div: 3257.4561\n",
      "Epoch[12/15], Step [210/469], Reconst Loss: 10338.4609, KL Div: 3255.7896\n",
      "Epoch[12/15], Step [220/469], Reconst Loss: 10339.9932, KL Div: 3213.7061\n",
      "Epoch[12/15], Step [230/469], Reconst Loss: 10443.6152, KL Div: 3230.4702\n",
      "Epoch[12/15], Step [240/469], Reconst Loss: 10145.4727, KL Div: 3180.2842\n",
      "Epoch[12/15], Step [250/469], Reconst Loss: 10502.7539, KL Div: 3247.7017\n",
      "Epoch[12/15], Step [260/469], Reconst Loss: 10588.1797, KL Div: 3299.9736\n",
      "Epoch[12/15], Step [270/469], Reconst Loss: 10267.7100, KL Div: 3259.1770\n",
      "Epoch[12/15], Step [280/469], Reconst Loss: 10079.2344, KL Div: 3175.1111\n",
      "Epoch[12/15], Step [290/469], Reconst Loss: 10079.5723, KL Div: 3157.0217\n",
      "Epoch[12/15], Step [300/469], Reconst Loss: 10088.0703, KL Div: 3226.3914\n",
      "Epoch[12/15], Step [310/469], Reconst Loss: 10222.9170, KL Div: 3173.4551\n",
      "Epoch[12/15], Step [320/469], Reconst Loss: 9734.2354, KL Div: 3098.8418\n",
      "Epoch[12/15], Step [330/469], Reconst Loss: 10427.5859, KL Div: 3247.5227\n",
      "Epoch[12/15], Step [340/469], Reconst Loss: 9897.7197, KL Div: 3145.9277\n",
      "Epoch[12/15], Step [350/469], Reconst Loss: 10238.7500, KL Div: 3307.7290\n",
      "Epoch[12/15], Step [360/469], Reconst Loss: 9654.0020, KL Div: 3195.8506\n",
      "Epoch[12/15], Step [370/469], Reconst Loss: 9941.5879, KL Div: 3193.5171\n",
      "Epoch[12/15], Step [380/469], Reconst Loss: 9706.7002, KL Div: 3202.5986\n",
      "Epoch[12/15], Step [390/469], Reconst Loss: 10504.9668, KL Div: 3347.5598\n",
      "Epoch[12/15], Step [400/469], Reconst Loss: 10122.7080, KL Div: 3238.1123\n",
      "Epoch[12/15], Step [410/469], Reconst Loss: 10280.5771, KL Div: 3286.7534\n",
      "Epoch[12/15], Step [420/469], Reconst Loss: 10305.2803, KL Div: 3244.1904\n",
      "Epoch[12/15], Step [430/469], Reconst Loss: 9949.7617, KL Div: 3211.1675\n",
      "Epoch[12/15], Step [440/469], Reconst Loss: 10173.3457, KL Div: 3229.0713\n",
      "Epoch[12/15], Step [450/469], Reconst Loss: 10542.4688, KL Div: 3297.7690\n",
      "Epoch[12/15], Step [460/469], Reconst Loss: 10290.1748, KL Div: 3257.3745\n",
      "Epoch[13/15], Step [10/469], Reconst Loss: 10203.4258, KL Div: 3263.2861\n",
      "Epoch[13/15], Step [20/469], Reconst Loss: 9895.1182, KL Div: 3173.4199\n",
      "Epoch[13/15], Step [30/469], Reconst Loss: 10471.4414, KL Div: 3258.1924\n",
      "Epoch[13/15], Step [40/469], Reconst Loss: 10021.8955, KL Div: 3201.8962\n",
      "Epoch[13/15], Step [50/469], Reconst Loss: 9954.6064, KL Div: 3064.6555\n",
      "Epoch[13/15], Step [60/469], Reconst Loss: 10054.4873, KL Div: 3212.3909\n",
      "Epoch[13/15], Step [70/469], Reconst Loss: 10248.2959, KL Div: 3266.4136\n",
      "Epoch[13/15], Step [80/469], Reconst Loss: 10054.1016, KL Div: 3115.0398\n",
      "Epoch[13/15], Step [90/469], Reconst Loss: 10301.2021, KL Div: 3235.3123\n",
      "Epoch[13/15], Step [100/469], Reconst Loss: 9918.0908, KL Div: 3178.5835\n",
      "Epoch[13/15], Step [110/469], Reconst Loss: 10676.3223, KL Div: 3248.1089\n",
      "Epoch[13/15], Step [120/469], Reconst Loss: 10595.6279, KL Div: 3267.1692\n",
      "Epoch[13/15], Step [130/469], Reconst Loss: 10662.5244, KL Div: 3329.3892\n",
      "Epoch[13/15], Step [140/469], Reconst Loss: 10045.8047, KL Div: 3103.9224\n",
      "Epoch[13/15], Step [150/469], Reconst Loss: 10545.5664, KL Div: 3345.6865\n",
      "Epoch[13/15], Step [160/469], Reconst Loss: 10559.2666, KL Div: 3211.4902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[13/15], Step [170/469], Reconst Loss: 9550.9053, KL Div: 3157.5466\n",
      "Epoch[13/15], Step [180/469], Reconst Loss: 9938.2354, KL Div: 3121.9614\n",
      "Epoch[13/15], Step [190/469], Reconst Loss: 9817.1113, KL Div: 3174.6572\n",
      "Epoch[13/15], Step [200/469], Reconst Loss: 10407.4111, KL Div: 3147.9771\n",
      "Epoch[13/15], Step [210/469], Reconst Loss: 10226.3848, KL Div: 3259.4590\n",
      "Epoch[13/15], Step [220/469], Reconst Loss: 10079.1201, KL Div: 3261.5703\n",
      "Epoch[13/15], Step [230/469], Reconst Loss: 10324.0391, KL Div: 3213.6611\n",
      "Epoch[13/15], Step [240/469], Reconst Loss: 10397.9756, KL Div: 3271.1311\n",
      "Epoch[13/15], Step [250/469], Reconst Loss: 10107.7363, KL Div: 3182.0117\n",
      "Epoch[13/15], Step [260/469], Reconst Loss: 10135.4346, KL Div: 3310.2300\n",
      "Epoch[13/15], Step [270/469], Reconst Loss: 10530.1436, KL Div: 3311.3521\n",
      "Epoch[13/15], Step [280/469], Reconst Loss: 10351.5957, KL Div: 3235.7854\n",
      "Epoch[13/15], Step [290/469], Reconst Loss: 10235.3740, KL Div: 3194.0508\n",
      "Epoch[13/15], Step [300/469], Reconst Loss: 10193.0947, KL Div: 3260.9568\n",
      "Epoch[13/15], Step [310/469], Reconst Loss: 10301.7490, KL Div: 3114.8120\n",
      "Epoch[13/15], Step [320/469], Reconst Loss: 10283.6572, KL Div: 3146.4250\n",
      "Epoch[13/15], Step [330/469], Reconst Loss: 10147.2090, KL Div: 3236.6377\n",
      "Epoch[13/15], Step [340/469], Reconst Loss: 10224.7129, KL Div: 3255.5522\n",
      "Epoch[13/15], Step [350/469], Reconst Loss: 10550.1641, KL Div: 3230.9668\n",
      "Epoch[13/15], Step [360/469], Reconst Loss: 10232.3135, KL Div: 3235.3943\n",
      "Epoch[13/15], Step [370/469], Reconst Loss: 10013.6836, KL Div: 3190.6338\n",
      "Epoch[13/15], Step [380/469], Reconst Loss: 9973.0928, KL Div: 3242.1831\n",
      "Epoch[13/15], Step [390/469], Reconst Loss: 10000.6074, KL Div: 3196.6699\n",
      "Epoch[13/15], Step [400/469], Reconst Loss: 9948.7803, KL Div: 3231.1353\n",
      "Epoch[13/15], Step [410/469], Reconst Loss: 10192.0498, KL Div: 3245.4258\n",
      "Epoch[13/15], Step [420/469], Reconst Loss: 10393.2773, KL Div: 3281.5483\n",
      "Epoch[13/15], Step [430/469], Reconst Loss: 10560.2383, KL Div: 3210.0732\n",
      "Epoch[13/15], Step [440/469], Reconst Loss: 10107.1621, KL Div: 3344.3345\n",
      "Epoch[13/15], Step [450/469], Reconst Loss: 10289.1016, KL Div: 3297.6179\n",
      "Epoch[13/15], Step [460/469], Reconst Loss: 10071.7324, KL Div: 3239.0322\n",
      "Epoch[14/15], Step [10/469], Reconst Loss: 10451.0000, KL Div: 3230.1670\n",
      "Epoch[14/15], Step [20/469], Reconst Loss: 10159.8203, KL Div: 3258.0581\n",
      "Epoch[14/15], Step [30/469], Reconst Loss: 10274.0508, KL Div: 3321.0613\n",
      "Epoch[14/15], Step [40/469], Reconst Loss: 10452.7988, KL Div: 3272.9546\n",
      "Epoch[14/15], Step [50/469], Reconst Loss: 10056.6289, KL Div: 3209.0842\n",
      "Epoch[14/15], Step [60/469], Reconst Loss: 10329.2979, KL Div: 3285.2246\n",
      "Epoch[14/15], Step [70/469], Reconst Loss: 10453.6641, KL Div: 3237.5669\n",
      "Epoch[14/15], Step [80/469], Reconst Loss: 10046.8330, KL Div: 3223.1433\n",
      "Epoch[14/15], Step [90/469], Reconst Loss: 10282.3682, KL Div: 3243.0732\n",
      "Epoch[14/15], Step [100/469], Reconst Loss: 10357.3125, KL Div: 3268.4944\n",
      "Epoch[14/15], Step [110/469], Reconst Loss: 10424.1660, KL Div: 3242.0845\n",
      "Epoch[14/15], Step [120/469], Reconst Loss: 10164.8096, KL Div: 3312.4927\n",
      "Epoch[14/15], Step [130/469], Reconst Loss: 10154.8906, KL Div: 3283.5566\n",
      "Epoch[14/15], Step [140/469], Reconst Loss: 9743.5273, KL Div: 3068.9878\n",
      "Epoch[14/15], Step [150/469], Reconst Loss: 10418.0938, KL Div: 3312.5442\n",
      "Epoch[14/15], Step [160/469], Reconst Loss: 10271.6504, KL Div: 3152.6152\n",
      "Epoch[14/15], Step [170/469], Reconst Loss: 9961.0273, KL Div: 3253.1196\n",
      "Epoch[14/15], Step [180/469], Reconst Loss: 10126.9336, KL Div: 3194.8535\n",
      "Epoch[14/15], Step [190/469], Reconst Loss: 10478.9502, KL Div: 3276.2446\n",
      "Epoch[14/15], Step [200/469], Reconst Loss: 9723.1582, KL Div: 3160.6675\n",
      "Epoch[14/15], Step [210/469], Reconst Loss: 10086.5645, KL Div: 3288.2996\n",
      "Epoch[14/15], Step [220/469], Reconst Loss: 10086.0537, KL Div: 3065.5383\n",
      "Epoch[14/15], Step [230/469], Reconst Loss: 10378.7607, KL Div: 3261.2109\n",
      "Epoch[14/15], Step [240/469], Reconst Loss: 10142.0176, KL Div: 3251.5437\n",
      "Epoch[14/15], Step [250/469], Reconst Loss: 9931.9082, KL Div: 3209.4265\n",
      "Epoch[14/15], Step [260/469], Reconst Loss: 10451.4395, KL Div: 3223.5896\n",
      "Epoch[14/15], Step [270/469], Reconst Loss: 10279.9873, KL Div: 3238.8760\n",
      "Epoch[14/15], Step [280/469], Reconst Loss: 10187.1982, KL Div: 3252.3191\n",
      "Epoch[14/15], Step [290/469], Reconst Loss: 10354.1465, KL Div: 3323.0562\n",
      "Epoch[14/15], Step [300/469], Reconst Loss: 10206.0391, KL Div: 3178.8296\n",
      "Epoch[14/15], Step [310/469], Reconst Loss: 10059.3750, KL Div: 3107.4617\n",
      "Epoch[14/15], Step [320/469], Reconst Loss: 10172.2285, KL Div: 3290.6990\n",
      "Epoch[14/15], Step [330/469], Reconst Loss: 10550.1699, KL Div: 3229.8896\n",
      "Epoch[14/15], Step [340/469], Reconst Loss: 10159.3701, KL Div: 3214.7429\n",
      "Epoch[14/15], Step [350/469], Reconst Loss: 10304.3447, KL Div: 3244.6572\n",
      "Epoch[14/15], Step [360/469], Reconst Loss: 9965.6846, KL Div: 3212.0527\n",
      "Epoch[14/15], Step [370/469], Reconst Loss: 10256.1328, KL Div: 3179.7288\n",
      "Epoch[14/15], Step [380/469], Reconst Loss: 10328.9561, KL Div: 3238.5000\n",
      "Epoch[14/15], Step [390/469], Reconst Loss: 10244.3281, KL Div: 3184.1294\n",
      "Epoch[14/15], Step [400/469], Reconst Loss: 10032.7559, KL Div: 3225.0703\n",
      "Epoch[14/15], Step [410/469], Reconst Loss: 10073.2891, KL Div: 3246.2188\n",
      "Epoch[14/15], Step [420/469], Reconst Loss: 10361.5322, KL Div: 3190.0381\n",
      "Epoch[14/15], Step [430/469], Reconst Loss: 10170.0488, KL Div: 3242.0500\n",
      "Epoch[14/15], Step [440/469], Reconst Loss: 10382.4658, KL Div: 3179.5693\n",
      "Epoch[14/15], Step [450/469], Reconst Loss: 10148.2070, KL Div: 3160.7246\n",
      "Epoch[14/15], Step [460/469], Reconst Loss: 10450.5830, KL Div: 3276.4404\n",
      "Epoch[15/15], Step [10/469], Reconst Loss: 10254.6006, KL Div: 3188.0264\n",
      "Epoch[15/15], Step [20/469], Reconst Loss: 10469.1953, KL Div: 3308.8760\n",
      "Epoch[15/15], Step [30/469], Reconst Loss: 10533.6240, KL Div: 3232.7622\n",
      "Epoch[15/15], Step [40/469], Reconst Loss: 10182.1191, KL Div: 3277.9175\n",
      "Epoch[15/15], Step [50/469], Reconst Loss: 10336.4824, KL Div: 3268.5156\n",
      "Epoch[15/15], Step [60/469], Reconst Loss: 9891.2383, KL Div: 3202.4087\n",
      "Epoch[15/15], Step [70/469], Reconst Loss: 10586.4629, KL Div: 3185.6609\n",
      "Epoch[15/15], Step [80/469], Reconst Loss: 10844.8193, KL Div: 3260.2817\n",
      "Epoch[15/15], Step [90/469], Reconst Loss: 10126.1777, KL Div: 3301.2324\n",
      "Epoch[15/15], Step [100/469], Reconst Loss: 9746.8184, KL Div: 3245.6748\n",
      "Epoch[15/15], Step [110/469], Reconst Loss: 10510.8730, KL Div: 3258.3608\n",
      "Epoch[15/15], Step [120/469], Reconst Loss: 10012.3945, KL Div: 3163.7334\n",
      "Epoch[15/15], Step [130/469], Reconst Loss: 10410.3857, KL Div: 3262.2585\n",
      "Epoch[15/15], Step [140/469], Reconst Loss: 10177.6260, KL Div: 3159.0435\n",
      "Epoch[15/15], Step [150/469], Reconst Loss: 10029.2598, KL Div: 3152.9829\n",
      "Epoch[15/15], Step [160/469], Reconst Loss: 9804.6543, KL Div: 3152.5947\n",
      "Epoch[15/15], Step [170/469], Reconst Loss: 10117.0918, KL Div: 3171.8044\n",
      "Epoch[15/15], Step [180/469], Reconst Loss: 10053.9951, KL Div: 3184.0962\n",
      "Epoch[15/15], Step [190/469], Reconst Loss: 10323.3574, KL Div: 3200.6289\n",
      "Epoch[15/15], Step [200/469], Reconst Loss: 10122.8535, KL Div: 3162.3750\n",
      "Epoch[15/15], Step [210/469], Reconst Loss: 9672.9824, KL Div: 3256.1189\n",
      "Epoch[15/15], Step [220/469], Reconst Loss: 10062.2539, KL Div: 3277.3801\n",
      "Epoch[15/15], Step [230/469], Reconst Loss: 10065.9717, KL Div: 3170.6340\n",
      "Epoch[15/15], Step [240/469], Reconst Loss: 10006.5508, KL Div: 3211.8760\n",
      "Epoch[15/15], Step [250/469], Reconst Loss: 10452.5273, KL Div: 3287.7080\n",
      "Epoch[15/15], Step [260/469], Reconst Loss: 10479.4092, KL Div: 3242.1660\n",
      "Epoch[15/15], Step [270/469], Reconst Loss: 10210.5928, KL Div: 3288.0508\n",
      "Epoch[15/15], Step [280/469], Reconst Loss: 10058.8301, KL Div: 3325.9941\n",
      "Epoch[15/15], Step [290/469], Reconst Loss: 10724.2090, KL Div: 3233.1450\n",
      "Epoch[15/15], Step [300/469], Reconst Loss: 10032.3193, KL Div: 3193.1538\n",
      "Epoch[15/15], Step [310/469], Reconst Loss: 10302.0234, KL Div: 3280.6914\n",
      "Epoch[15/15], Step [320/469], Reconst Loss: 10274.5293, KL Div: 3256.6621\n",
      "Epoch[15/15], Step [330/469], Reconst Loss: 10452.4541, KL Div: 3304.1289\n",
      "Epoch[15/15], Step [340/469], Reconst Loss: 10457.4287, KL Div: 3153.3303\n",
      "Epoch[15/15], Step [350/469], Reconst Loss: 10233.9180, KL Div: 3263.1880\n",
      "Epoch[15/15], Step [360/469], Reconst Loss: 10117.8770, KL Div: 3148.0483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[15/15], Step [370/469], Reconst Loss: 10241.6484, KL Div: 3210.5330\n",
      "Epoch[15/15], Step [380/469], Reconst Loss: 10209.1660, KL Div: 3190.0989\n",
      "Epoch[15/15], Step [390/469], Reconst Loss: 10110.5293, KL Div: 3260.5461\n",
      "Epoch[15/15], Step [400/469], Reconst Loss: 10416.2461, KL Div: 3282.9731\n",
      "Epoch[15/15], Step [410/469], Reconst Loss: 9860.9365, KL Div: 3117.5310\n",
      "Epoch[15/15], Step [420/469], Reconst Loss: 9955.3359, KL Div: 3177.5771\n",
      "Epoch[15/15], Step [430/469], Reconst Loss: 10450.8203, KL Div: 3373.6338\n",
      "Epoch[15/15], Step [440/469], Reconst Loss: 10431.3633, KL Div: 3140.9524\n",
      "Epoch[15/15], Step [450/469], Reconst Loss: 9851.7510, KL Div: 3263.5271\n",
      "Epoch[15/15], Step [460/469], Reconst Loss: 10182.3340, KL Div: 3250.8943\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "        # Forward pass\n",
    "        x = x.to(device).reshape(-1, image_size)\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "\n",
    "        # Compute reconstruction loss and kl divergence\n",
    "        # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "        # Backprop and optimize\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \n",
    "                   .format(epoch + 1, num_epochs, i + 1, len(data_loader), reconst_loss.item(), kl_div.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bbd6716a2afa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch + 1)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qhmtorch/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2675\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2677\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2678\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qhmtorch/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qhmtorch/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qhmtorch/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qhmtorch/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5677\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5679\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5680\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qhmtorch/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Needed e.g. to apply png palette.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_masked_invalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         if (self._A.dtype != np.uint8 and\n",
      "\u001b[0;32m~/miniconda3/envs/qhmtorch/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36msafe_masked_invalid\u001b[0;34m(x, copy)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msafe_masked_invalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnative\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0;31m# Note that the argument to `byteswap` is 'inplace',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qhmtorch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Save the sampled images\n",
    "    z = torch.randn(batch_size, z_dim).to(device)\n",
    "    out = model.decode(z).reshape(-1, 1, 28, 28)\n",
    "    for i in range(5):\n",
    "        plt.figure()\n",
    "        plt.imshow(out[i].reshape(28, 28))\n",
    "        plt.show()\n",
    "    # save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch + 1)))\n",
    "\n",
    "    # Save the reconstructed images\n",
    "    out, _, _ = model(x)\n",
    "    x_concat = torch.cat([x.reshape(-1, 1, 28, 28), out.reshape(-1, 1, 28, 28)], dim=3)\n",
    "    for i in range(5):\n",
    "        plt.figure()\n",
    "        plt.imshow(x_concat[i].reshape(28, 56))\n",
    "        plt.show()\n",
    "    # save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch + 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qhmtorch",
   "language": "python",
   "name": "qhmtorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
