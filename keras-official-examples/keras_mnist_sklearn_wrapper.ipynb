{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Example of how to use sklearn wrapper\n",
    "\n",
    "Builds simple CNN models on MNIST and uses sklearn's GridSearchCV to find best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunxin/miniconda3/envs/qinhanmin-test/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sunxin/miniconda3/envs/qinhanmin-test/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sunxin/miniconda3/envs/qinhanmin-test/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sunxin/miniconda3/envs/qinhanmin-test/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sunxin/miniconda3/envs/qinhanmin-test/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sunxin/miniconda3/envs/qinhanmin-test/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.2\n",
      "2.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# load training data and do basic data normalization\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(dense_layer_sizes, filters, kernel_size, pool_size):\n",
    "    '''Creates model comprised of 2 convolutional layers followed by dense layers\n",
    "    dense_layer_sizes: List of layer sizes.\n",
    "        This list has one number for each layer\n",
    "    filters: Number of convolutional filters in each convolutional layer\n",
    "    kernel_size: Convolutional kernel size\n",
    "    pool_size: Size of pooling area for max pooling\n",
    "    '''\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters, kernel_size,\n",
    "                            padding='valid',\n",
    "                            input_shape=input_shape))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.Conv2D(filters, kernel_size))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    for layer_size in dense_layer_sizes:\n",
    "        model.add(layers.Dense(layer_size))\n",
    "        model.add(layers.Activation('relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes))\n",
    "    model.add(layers.Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sunxin/miniconda3/envs/qinhanmin-test/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/sunxin/miniconda3/envs/qinhanmin-test/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunxin/miniconda3/envs/qinhanmin-test/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sunxin/miniconda3/envs/qinhanmin-test/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 0.6343 - acc: 0.7911\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 0.3780 - acc: 0.8793\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 7s 182us/step - loss: 0.3114 - acc: 0.9017\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.7124 - acc: 0.7607\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 0.3921 - acc: 0.8736\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.3130 - acc: 0.9034\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.6531 - acc: 0.7866\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.3753 - acc: 0.8829\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.3016 - acc: 0.9097\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 0.5821 - acc: 0.8082\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.3469 - acc: 0.8891\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.3059 - acc: 0.9028\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 0.2672 - acc: 0.9177\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.2537 - acc: 0.9194\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.2442 - acc: 0.9246\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 8s 199us/step - loss: 0.6176 - acc: 0.8001\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.3539 - acc: 0.8900\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.3018 - acc: 0.9051\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.2732 - acc: 0.9159\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.2511 - acc: 0.9229\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.2422 - acc: 0.9248\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 8s 201us/step - loss: 0.6080 - acc: 0.7989\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.3678 - acc: 0.8843\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.3084 - acc: 0.9039\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 0.2847 - acc: 0.9109\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.2584 - acc: 0.9193\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.2461 - acc: 0.9236\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 8s 204us/step - loss: 0.4748 - acc: 0.8508\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 0.2250 - acc: 0.9344\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.1715 - acc: 0.9503\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 8s 203us/step - loss: 0.4565 - acc: 0.8593\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.2325 - acc: 0.9318\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.1859 - acc: 0.9465\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 8s 206us/step - loss: 0.4464 - acc: 0.8599\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.2158 - acc: 0.9362\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.1725 - acc: 0.9497\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 8s 208us/step - loss: 0.4300 - acc: 0.8668\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.2119 - acc: 0.9379\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.1697 - acc: 0.9504\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 8s 191us/step - loss: 0.1481 - acc: 0.9567\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.1366 - acc: 0.9612\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.1273 - acc: 0.9625\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 8s 210us/step - loss: 0.4497 - acc: 0.8622\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.2262 - acc: 0.9345\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.1819 - acc: 0.9472\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.1647 - acc: 0.9524\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.1476 - acc: 0.9570\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.1406 - acc: 0.9599\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 9s 213us/step - loss: 0.4582 - acc: 0.8585\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 0.2293 - acc: 0.9331\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.1861 - acc: 0.9465\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 8s 194us/step - loss: 0.1605 - acc: 0.9529\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.1411 - acc: 0.9599\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 8s 193us/step - loss: 0.1340 - acc: 0.9611\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 0.5957 - acc: 0.8065\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 0.3186 - acc: 0.9025\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 8s 210us/step - loss: 0.2697 - acc: 0.9180\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 0.6140 - acc: 0.7997\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 8s 211us/step - loss: 0.3001 - acc: 0.9123\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 0.2402 - acc: 0.9309\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 0.5761 - acc: 0.8170\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 8s 211us/step - loss: 0.2867 - acc: 0.9166\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 8s 211us/step - loss: 0.2282 - acc: 0.9343\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 0.5545 - acc: 0.8195\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 8s 211us/step - loss: 0.2897 - acc: 0.9128\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 8s 211us/step - loss: 0.2338 - acc: 0.9297\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 8s 211us/step - loss: 0.2028 - acc: 0.9420\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 8s 211us/step - loss: 0.1854 - acc: 0.9476\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 8s 212us/step - loss: 0.1677 - acc: 0.9535\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 0.5431 - acc: 0.8269\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 8s 212us/step - loss: 0.2727 - acc: 0.9197\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 8s 212us/step - loss: 0.2144 - acc: 0.9372\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 9s 213us/step - loss: 0.1892 - acc: 0.9449\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 9s 213us/step - loss: 0.1680 - acc: 0.9498\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 9s 213us/step - loss: 0.1581 - acc: 0.9548\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 0.5362 - acc: 0.8286\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 8s 212us/step - loss: 0.2677 - acc: 0.9190\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 9s 216us/step - loss: 0.2205 - acc: 0.9352\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 9s 213us/step - loss: 0.1841 - acc: 0.9470\n",
      "Epoch 5/6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 9s 214us/step - loss: 0.1630 - acc: 0.9499\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 8s 212us/step - loss: 0.1497 - acc: 0.9555\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 10s 249us/step - loss: 0.4054 - acc: 0.8763\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 0.1727 - acc: 0.9527\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 9s 215us/step - loss: 0.1291 - acc: 0.9655\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 10s 249us/step - loss: 0.4359 - acc: 0.8665\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 0.1746 - acc: 0.9511\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 9s 214us/step - loss: 0.1329 - acc: 0.9638\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 10s 254us/step - loss: 0.3810 - acc: 0.8852\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 0.1539 - acc: 0.9578\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 9s 215us/step - loss: 0.1156 - acc: 0.9685\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 10s 255us/step - loss: 0.3833 - acc: 0.8823\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 0.1532 - acc: 0.9585\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 0.1161 - acc: 0.9682\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 9s 216us/step - loss: 0.1009 - acc: 0.9732\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 9s 216us/step - loss: 0.0905 - acc: 0.9754\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 0.0805 - acc: 0.9781\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 10s 260us/step - loss: 0.3611 - acc: 0.8904\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 0.1537 - acc: 0.9583\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 0.1196 - acc: 0.9683\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 0.1022 - acc: 0.9728\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 0.0937 - acc: 0.9752\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 9s 220us/step - loss: 0.0855 - acc: 0.9781\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 10s 262us/step - loss: 0.3624 - acc: 0.8905\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 0.1558 - acc: 0.9572\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 0.1217 - acc: 0.9674\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 0.1012 - acc: 0.9727\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 0.0905 - acc: 0.9753\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 9s 220us/step - loss: 0.0838 - acc: 0.9777\n",
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 15s 250us/step - loss: 0.3248 - acc: 0.9027\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.1374 - acc: 0.9626\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.1080 - acc: 0.9712\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 13s 218us/step - loss: 0.0906 - acc: 0.9758\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.0815 - acc: 0.9786\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 0.0761 - acc: 0.9804\n",
      "The parameters of the best model are: \n",
      "{'dense_layer_sizes': [64, 64], 'epochs': 6, 'filters': 8, 'kernel_size': 3, 'pool_size': 2}\n"
     ]
    }
   ],
   "source": [
    "dense_size_candidates = [[32], [64], [32, 32], [64, 64]]\n",
    "my_classifier = KerasClassifier(make_model, batch_size=32)\n",
    "validator = GridSearchCV(my_classifier,\n",
    "                         param_grid={'dense_layer_sizes': dense_size_candidates,\n",
    "                                     # epochs is avail for tuning even when not\n",
    "                                     # an argument to model building function\n",
    "                                     'epochs': [3, 6],\n",
    "                                     'filters': [8],\n",
    "                                     'kernel_size': [3],\n",
    "                                     'pool_size': [2]},\n",
    "                         scoring='neg_log_loss',\n",
    "                         n_jobs=1)\n",
    "validator.fit(x_train, y_train)\n",
    "\n",
    "print('The parameters of the best model are: ')\n",
    "print(validator.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 140us/step\n",
      "loss :  0.04639862526347424\n",
      "acc :  0.986\n"
     ]
    }
   ],
   "source": [
    "# validator.best_estimator_ returns sklearn-wrapped version of best model.\n",
    "# validator.best_estimator_.model returns the (unwrapped) keras model\n",
    "best_model = validator.best_estimator_.model\n",
    "metric_names = best_model.metrics_names\n",
    "metric_values = best_model.evaluate(x_test, y_test)\n",
    "for metric, value in zip(metric_names, metric_values):\n",
    "    print(metric, ': ', value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qinhanmin-test",
   "language": "python",
   "name": "qinhanmin-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
