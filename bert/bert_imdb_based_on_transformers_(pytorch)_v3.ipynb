{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3\"\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 256\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE_MODEL = 1e-5\n",
    "LEARNING_RATE_CLASSIFIER = 1e-3\n",
    "WARMUP_STEPS = 0\n",
    "MAX_GRAD_NORM = 1\n",
    "GRADIENT_ACCUMULATION_STEPS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 1024)\n",
       "        (token_type_embeddings): Embedding(2, 1024)\n",
       "        (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (12): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (13): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (14): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (15): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (16): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (17): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (18): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (19): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (20): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (21): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (22): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (23): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1)\n",
       "    (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\", num_labels=2)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:52<00:00, 240.23it/s]\n",
      "100%|██████████| 12500/12500 [00:54<00:00, 231.41it/s]\n",
      "100%|██████████| 12500/12500 [00:51<00:00, 242.65it/s]\n",
      "100%|██████████| 12500/12500 [00:52<00:00, 238.79it/s]\n"
     ]
    }
   ],
   "source": [
    "def _parse_imdb_line(line):\n",
    "    line = re.sub(r\"<br \\/>\", \" \", line)\n",
    "    return line\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    indices, sentiments = [], []\n",
    "    for folder, sentiment in (('neg', 0), ('pos', 1)):\n",
    "        folder = os.path.join(path, folder)\n",
    "        for name in tqdm(os.listdir(folder)):\n",
    "            with open(os.path.join(folder, name), 'r') as reader:\n",
    "                  text = _parse_imdb_line(reader.read())\n",
    "            ids = tokenizer.encode(text, max_length=MAX_SEQ_LENGTH, pad_to_max_length=True)\n",
    "            indices.append(ids)\n",
    "            sentiments.append(sentiment)\n",
    "    return np.array(indices), np.array(sentiments)\n",
    "\n",
    "\n",
    "train_path = os.path.join(\"../datasets\", 'aclImdb', 'train')\n",
    "test_path = os.path.join(\"../datasets\", 'aclImdb', 'test')\n",
    "X_train, y_train = load_data(train_path)\n",
    "X_test, y_test = load_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.long)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/6250], Loss: 0.1172\n",
      "Epoch [1/5], Step [200/6250], Loss: 0.1167\n",
      "Epoch [1/5], Step [300/6250], Loss: 0.1562\n",
      "Epoch [1/5], Step [400/6250], Loss: 0.1158\n",
      "Epoch [1/5], Step [500/6250], Loss: 0.0507\n",
      "Epoch [1/5], Step [600/6250], Loss: 0.0329\n",
      "Epoch [1/5], Step [700/6250], Loss: 0.0147\n",
      "Epoch [1/5], Step [800/6250], Loss: 0.0256\n",
      "Epoch [1/5], Step [900/6250], Loss: 0.0037\n",
      "Epoch [1/5], Step [1000/6250], Loss: 0.0201\n",
      "Epoch [1/5], Step [1100/6250], Loss: 0.0091\n",
      "Epoch [1/5], Step [1200/6250], Loss: 0.0039\n",
      "Epoch [1/5], Step [1300/6250], Loss: 0.0012\n",
      "Epoch [1/5], Step [1400/6250], Loss: 0.0041\n",
      "Epoch [1/5], Step [1500/6250], Loss: 0.0128\n",
      "Epoch [1/5], Step [1600/6250], Loss: 0.0246\n",
      "Epoch [1/5], Step [1700/6250], Loss: 0.2041\n",
      "Epoch [1/5], Step [1800/6250], Loss: 0.0426\n",
      "Epoch [1/5], Step [1900/6250], Loss: 0.1126\n",
      "Epoch [1/5], Step [2000/6250], Loss: 0.0154\n",
      "Epoch [1/5], Step [2100/6250], Loss: 0.0445\n",
      "Epoch [1/5], Step [2200/6250], Loss: 0.0011\n",
      "Epoch [1/5], Step [2300/6250], Loss: 0.0058\n",
      "Epoch [1/5], Step [2400/6250], Loss: 0.0102\n",
      "Epoch [1/5], Step [2500/6250], Loss: 0.0024\n",
      "Epoch [1/5], Step [2600/6250], Loss: 0.0066\n",
      "Epoch [1/5], Step [2700/6250], Loss: 0.0046\n",
      "Epoch [1/5], Step [2800/6250], Loss: 0.0517\n",
      "Epoch [1/5], Step [2900/6250], Loss: 0.2695\n",
      "Epoch [1/5], Step [3000/6250], Loss: 0.0752\n",
      "Epoch [1/5], Step [3100/6250], Loss: 0.1378\n",
      "Epoch [1/5], Step [3200/6250], Loss: 0.0166\n",
      "Epoch [1/5], Step [3300/6250], Loss: 0.0274\n",
      "Epoch [1/5], Step [3400/6250], Loss: 0.0075\n",
      "Epoch [1/5], Step [3500/6250], Loss: 0.0333\n",
      "Epoch [1/5], Step [3600/6250], Loss: 0.1609\n",
      "Epoch [1/5], Step [3700/6250], Loss: 0.0466\n",
      "Epoch [1/5], Step [3800/6250], Loss: 0.0020\n",
      "Epoch [1/5], Step [3900/6250], Loss: 0.1885\n",
      "Epoch [1/5], Step [4000/6250], Loss: 0.1546\n",
      "Epoch [1/5], Step [4100/6250], Loss: 0.0514\n",
      "Epoch [1/5], Step [4200/6250], Loss: 0.0048\n",
      "Epoch [1/5], Step [4300/6250], Loss: 0.2370\n",
      "Epoch [1/5], Step [4400/6250], Loss: 0.0095\n",
      "Epoch [1/5], Step [4500/6250], Loss: 0.0600\n",
      "Epoch [1/5], Step [4600/6250], Loss: 0.1663\n",
      "Epoch [1/5], Step [4700/6250], Loss: 0.0101\n",
      "Epoch [1/5], Step [4800/6250], Loss: 0.0203\n",
      "Epoch [1/5], Step [4900/6250], Loss: 0.1028\n",
      "Epoch [1/5], Step [5000/6250], Loss: 0.0025\n",
      "Epoch [1/5], Step [5100/6250], Loss: 0.0030\n",
      "Epoch [1/5], Step [5200/6250], Loss: 0.0073\n",
      "Epoch [1/5], Step [5300/6250], Loss: 0.0080\n",
      "Epoch [1/5], Step [5400/6250], Loss: 0.0012\n",
      "Epoch [1/5], Step [5500/6250], Loss: 0.0136\n",
      "Epoch [1/5], Step [5600/6250], Loss: 0.1413\n",
      "Epoch [1/5], Step [5700/6250], Loss: 0.0936\n",
      "Epoch [1/5], Step [5800/6250], Loss: 0.0454\n",
      "Epoch [1/5], Step [5900/6250], Loss: 0.0035\n",
      "Epoch [1/5], Step [6000/6250], Loss: 0.0015\n",
      "Epoch [1/5], Step [6100/6250], Loss: 0.0014\n",
      "Epoch [1/5], Step [6200/6250], Loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [22:45<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.828 %\n",
      "Epoch [2/5], Step [100/6250], Loss: 0.0002\n",
      "Epoch [2/5], Step [200/6250], Loss: 0.0006\n",
      "Epoch [2/5], Step [300/6250], Loss: 0.0014\n",
      "Epoch [2/5], Step [400/6250], Loss: 0.0002\n",
      "Epoch [2/5], Step [500/6250], Loss: 0.0003\n",
      "Epoch [2/5], Step [600/6250], Loss: 0.0082\n",
      "Epoch [2/5], Step [700/6250], Loss: 0.0034\n",
      "Epoch [2/5], Step [800/6250], Loss: 0.0017\n",
      "Epoch [2/5], Step [900/6250], Loss: 0.0001\n",
      "Epoch [2/5], Step [1000/6250], Loss: 0.0007\n",
      "Epoch [2/5], Step [1100/6250], Loss: 0.0000\n",
      "Epoch [2/5], Step [1200/6250], Loss: 0.0004\n",
      "Epoch [2/5], Step [1300/6250], Loss: 0.0013\n",
      "Epoch [2/5], Step [1400/6250], Loss: 0.2141\n",
      "Epoch [2/5], Step [1500/6250], Loss: 0.0007\n",
      "Epoch [2/5], Step [1600/6250], Loss: 0.2006\n",
      "Epoch [2/5], Step [1700/6250], Loss: 0.0026\n",
      "Epoch [2/5], Step [1800/6250], Loss: 0.0003\n",
      "Epoch [2/5], Step [1900/6250], Loss: 0.0019\n",
      "Epoch [2/5], Step [2000/6250], Loss: 0.0100\n",
      "Epoch [2/5], Step [2100/6250], Loss: 0.0037\n",
      "Epoch [2/5], Step [2200/6250], Loss: 0.0010\n",
      "Epoch [2/5], Step [2300/6250], Loss: 0.0001\n",
      "Epoch [2/5], Step [2400/6250], Loss: 0.0011\n",
      "Epoch [2/5], Step [2500/6250], Loss: 0.0003\n",
      "Epoch [2/5], Step [2600/6250], Loss: 0.0002\n",
      "Epoch [2/5], Step [2700/6250], Loss: 0.0007\n",
      "Epoch [2/5], Step [2800/6250], Loss: 0.0002\n",
      "Epoch [2/5], Step [2900/6250], Loss: 0.0013\n",
      "Epoch [2/5], Step [3000/6250], Loss: 0.0023\n",
      "Epoch [2/5], Step [3100/6250], Loss: 0.0028\n",
      "Epoch [2/5], Step [3200/6250], Loss: 0.0201\n",
      "Epoch [2/5], Step [3300/6250], Loss: 0.0009\n",
      "Epoch [2/5], Step [3400/6250], Loss: 0.0006\n",
      "Epoch [2/5], Step [3500/6250], Loss: 0.0004\n",
      "Epoch [2/5], Step [3600/6250], Loss: 0.0048\n",
      "Epoch [2/5], Step [3700/6250], Loss: 0.0003\n",
      "Epoch [2/5], Step [3800/6250], Loss: 0.4116\n",
      "Epoch [2/5], Step [3900/6250], Loss: 0.0011\n",
      "Epoch [2/5], Step [4000/6250], Loss: 0.0048\n",
      "Epoch [2/5], Step [4100/6250], Loss: 0.0072\n",
      "Epoch [2/5], Step [4200/6250], Loss: 0.1455\n",
      "Epoch [2/5], Step [4300/6250], Loss: 0.0008\n",
      "Epoch [2/5], Step [4400/6250], Loss: 0.0015\n",
      "Epoch [2/5], Step [4500/6250], Loss: 0.0018\n",
      "Epoch [2/5], Step [4600/6250], Loss: 0.0002\n",
      "Epoch [2/5], Step [4700/6250], Loss: 0.0009\n",
      "Epoch [2/5], Step [4800/6250], Loss: 0.0012\n",
      "Epoch [2/5], Step [4900/6250], Loss: 0.0005\n",
      "Epoch [2/5], Step [5000/6250], Loss: 0.0011\n",
      "Epoch [2/5], Step [5100/6250], Loss: 0.0127\n",
      "Epoch [2/5], Step [5200/6250], Loss: 0.0009\n",
      "Epoch [2/5], Step [5300/6250], Loss: 0.0223\n",
      "Epoch [2/5], Step [5400/6250], Loss: 0.0036\n",
      "Epoch [2/5], Step [5500/6250], Loss: 0.0003\n",
      "Epoch [2/5], Step [5600/6250], Loss: 0.0082\n",
      "Epoch [2/5], Step [5700/6250], Loss: 0.2218\n",
      "Epoch [2/5], Step [5800/6250], Loss: 0.0003\n",
      "Epoch [2/5], Step [5900/6250], Loss: 0.0047\n",
      "Epoch [2/5], Step [6000/6250], Loss: 0.0009\n",
      "Epoch [2/5], Step [6100/6250], Loss: 0.1209\n",
      "Epoch [2/5], Step [6200/6250], Loss: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [22:24<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.576 %\n",
      "Epoch [3/5], Step [100/6250], Loss: 0.0006\n",
      "Epoch [3/5], Step [200/6250], Loss: 0.0003\n",
      "Epoch [3/5], Step [300/6250], Loss: 0.0001\n",
      "Epoch [3/5], Step [400/6250], Loss: 0.0005\n",
      "Epoch [3/5], Step [500/6250], Loss: 0.0007\n",
      "Epoch [3/5], Step [600/6250], Loss: 0.0598\n",
      "Epoch [3/5], Step [700/6250], Loss: 0.0001\n",
      "Epoch [3/5], Step [800/6250], Loss: 0.0003\n",
      "Epoch [3/5], Step [900/6250], Loss: 0.0002\n",
      "Epoch [3/5], Step [1000/6250], Loss: 0.0002\n",
      "Epoch [3/5], Step [1100/6250], Loss: 0.0001\n",
      "Epoch [3/5], Step [1200/6250], Loss: 0.0006\n",
      "Epoch [3/5], Step [1300/6250], Loss: 0.0476\n",
      "Epoch [3/5], Step [1400/6250], Loss: 0.0001\n",
      "Epoch [3/5], Step [1500/6250], Loss: 0.0002\n",
      "Epoch [3/5], Step [1600/6250], Loss: 0.0000\n",
      "Epoch [3/5], Step [1700/6250], Loss: 0.0018\n",
      "Epoch [3/5], Step [1800/6250], Loss: 0.0011\n",
      "Epoch [3/5], Step [1900/6250], Loss: 0.0001\n",
      "Epoch [3/5], Step [2000/6250], Loss: 0.0014\n",
      "Epoch [3/5], Step [2100/6250], Loss: 0.0002\n",
      "Epoch [3/5], Step [2200/6250], Loss: 0.0006\n",
      "Epoch [3/5], Step [2300/6250], Loss: 0.0007\n",
      "Epoch [3/5], Step [2400/6250], Loss: 0.0000\n",
      "Epoch [3/5], Step [2500/6250], Loss: 0.0008\n",
      "Epoch [3/5], Step [2600/6250], Loss: 0.0007\n",
      "Epoch [3/5], Step [2700/6250], Loss: 0.0000\n",
      "Epoch [3/5], Step [2800/6250], Loss: 0.0009\n",
      "Epoch [3/5], Step [2900/6250], Loss: 0.0002\n",
      "Epoch [3/5], Step [3000/6250], Loss: 0.0001\n",
      "Epoch [3/5], Step [3100/6250], Loss: 0.0000\n",
      "Epoch [3/5], Step [3200/6250], Loss: 0.0001\n",
      "Epoch [3/5], Step [3300/6250], Loss: 0.0002\n",
      "Epoch [3/5], Step [3400/6250], Loss: 0.0000\n",
      "Epoch [3/5], Step [3500/6250], Loss: 0.0001\n",
      "Epoch [3/5], Step [3600/6250], Loss: 0.1780\n",
      "Epoch [3/5], Step [3700/6250], Loss: 0.0048\n",
      "Epoch [3/5], Step [3800/6250], Loss: 0.0003\n",
      "Epoch [3/5], Step [3900/6250], Loss: 0.0001\n",
      "Epoch [3/5], Step [4000/6250], Loss: 0.0003\n",
      "Epoch [3/5], Step [4100/6250], Loss: 0.0006\n",
      "Epoch [3/5], Step [4200/6250], Loss: 0.0002\n",
      "Epoch [3/5], Step [4300/6250], Loss: 0.0003\n",
      "Epoch [3/5], Step [4400/6250], Loss: 0.0002\n",
      "Epoch [3/5], Step [4500/6250], Loss: 0.0002\n",
      "Epoch [3/5], Step [4600/6250], Loss: 0.0000\n",
      "Epoch [3/5], Step [4700/6250], Loss: 0.0004\n",
      "Epoch [3/5], Step [4800/6250], Loss: 0.1085\n",
      "Epoch [3/5], Step [4900/6250], Loss: 0.0001\n",
      "Epoch [3/5], Step [5000/6250], Loss: 0.0000\n",
      "Epoch [3/5], Step [5100/6250], Loss: 0.2654\n",
      "Epoch [3/5], Step [5200/6250], Loss: 0.0001\n",
      "Epoch [3/5], Step [5300/6250], Loss: 0.0013\n",
      "Epoch [3/5], Step [5400/6250], Loss: 0.0001\n",
      "Epoch [3/5], Step [5500/6250], Loss: 0.0002\n",
      "Epoch [3/5], Step [5600/6250], Loss: 0.0002\n",
      "Epoch [3/5], Step [5700/6250], Loss: 0.0007\n",
      "Epoch [3/5], Step [5800/6250], Loss: 0.4111\n",
      "Epoch [3/5], Step [5900/6250], Loss: 0.0001\n",
      "Epoch [3/5], Step [6000/6250], Loss: 0.2356\n",
      "Epoch [3/5], Step [6100/6250], Loss: 0.0003\n",
      "Epoch [3/5], Step [6200/6250], Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [22:24<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.196 %\n",
      "Epoch [4/5], Step [100/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [200/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [300/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [400/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [500/6250], Loss: 0.0005\n",
      "Epoch [4/5], Step [600/6250], Loss: 0.5662\n",
      "Epoch [4/5], Step [700/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [800/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [900/6250], Loss: 0.0003\n",
      "Epoch [4/5], Step [1000/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [1100/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [1200/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [1300/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [1400/6250], Loss: 0.0002\n",
      "Epoch [4/5], Step [1500/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [1600/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [1700/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [1800/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [1900/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [2000/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [2100/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [2200/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [2300/6250], Loss: 0.2600\n",
      "Epoch [4/5], Step [2400/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [2500/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [2600/6250], Loss: 0.0004\n",
      "Epoch [4/5], Step [2700/6250], Loss: 0.0002\n",
      "Epoch [4/5], Step [2800/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [2900/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [3000/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [3100/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [3200/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [3300/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [3400/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [3500/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [3600/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [3700/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [3800/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [3900/6250], Loss: 0.0008\n",
      "Epoch [4/5], Step [4000/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [4100/6250], Loss: 0.0002\n",
      "Epoch [4/5], Step [4200/6250], Loss: 0.0002\n",
      "Epoch [4/5], Step [4300/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [4400/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [4500/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [4600/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [4700/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [4800/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [4900/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [5000/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [5100/6250], Loss: 0.0042\n",
      "Epoch [4/5], Step [5200/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [5300/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [5400/6250], Loss: 0.5687\n",
      "Epoch [4/5], Step [5500/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [5600/6250], Loss: 0.0257\n",
      "Epoch [4/5], Step [5700/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [5800/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [5900/6250], Loss: 0.0001\n",
      "Epoch [4/5], Step [6000/6250], Loss: 0.0000\n",
      "Epoch [4/5], Step [6100/6250], Loss: 0.0004\n",
      "Epoch [4/5], Step [6200/6250], Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [22:24<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.536 %\n",
      "Epoch [5/5], Step [100/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [200/6250], Loss: 0.0001\n",
      "Epoch [5/5], Step [300/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [400/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [500/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [600/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [700/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [800/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [900/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [1000/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [1100/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [1200/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [1300/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [1400/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [1500/6250], Loss: 0.0001\n",
      "Epoch [5/5], Step [1600/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [1700/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [1800/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [1900/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [2000/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [2100/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [2200/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [2300/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [2400/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [2500/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [2600/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [2700/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [2800/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [2900/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [3000/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [3100/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [3200/6250], Loss: 0.3323\n",
      "Epoch [5/5], Step [3300/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [3400/6250], Loss: 0.0002\n",
      "Epoch [5/5], Step [3500/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [3600/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [3700/6250], Loss: 0.0001\n",
      "Epoch [5/5], Step [3800/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [3900/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [4000/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [4100/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [4200/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [4300/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [4400/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [4500/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [4600/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [4700/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [4800/6250], Loss: 0.0001\n",
      "Epoch [5/5], Step [4900/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [5000/6250], Loss: 0.0001\n",
      "Epoch [5/5], Step [5100/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [5200/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [5300/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [5400/6250], Loss: 0.0001\n",
      "Epoch [5/5], Step [5500/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [5600/6250], Loss: 0.3569\n",
      "Epoch [5/5], Step [5700/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [5800/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [5900/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [6000/6250], Loss: 0.0001\n",
      "Epoch [5/5], Step [6100/6250], Loss: 0.0000\n",
      "Epoch [5/5], Step [6200/6250], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [22:23<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.536 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer_grouped_parameters = [\n",
    "        {\"params\": model.module.bert.parameters(), \"lr\": LEARNING_RATE_MODEL},\n",
    "        {\"params\": model.module.classifier.parameters(), \"lr\": LEARNING_RATE_CLASSIFIER}\n",
    "    ]\n",
    "optimizer = AdamW(optimizer_grouped_parameters)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=WARMUP_STEPS,\n",
    "                num_training_steps=len(train_loader) // GRADIENT_ACCUMULATION_STEPS * NUM_EPOCHS)\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    for i, (cur_X_train, cur_y_train) in enumerate(train_loader):\n",
    "        cur_X_train = cur_X_train.to(device)\n",
    "        cur_y_train = cur_y_train.to(device)\n",
    "        outputs = model(cur_X_train)\n",
    "        loss = nn.CrossEntropyLoss()(outputs[0], cur_y_train)\n",
    "        loss /= GRADIENT_ACCUMULATION_STEPS\n",
    "        loss.backward()\n",
    "        if (i + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            model.zero_grad()\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch + 1, NUM_EPOCHS, i + 1, total_step, loss.item()))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for cur_X_test, cur_y_test in tqdm(test_loader):\n",
    "            cur_X_test = cur_X_test.to(device)\n",
    "            cur_y_test = cur_y_test.to(device)\n",
    "            outputs = model(cur_X_test)\n",
    "            _, predicted = torch.max(outputs[0], 1)\n",
    "            total += cur_y_test.size(0)\n",
    "            correct += (predicted == cur_y_test).sum().item()\n",
    "        print('Accuracy: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [22:23<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.536 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for cur_X_test, cur_y_test in tqdm(test_loader):\n",
    "        cur_X_test = cur_X_test.to(device)\n",
    "        cur_y_test = cur_y_test.to(device)\n",
    "        outputs = model(cur_X_test)\n",
    "        _, predicted = torch.max(outputs[0], 1)\n",
    "        total += cur_y_test.size(0)\n",
    "        correct += (predicted == cur_y_test).sum().item()\n",
    "    print('Accuracy: {} %'.format(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qhmtorch",
   "language": "python",
   "name": "qhmtorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
